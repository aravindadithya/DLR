Dataset transforms:
transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # Mean and standard deviation for MNIST
    ])

trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainset, valset = train_test_split(trainset, train_size=0.8)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, num_workers=2)
valloader = torch.utils.data.DataLoader(valset, batch_size=100,
                                            shuffle=False, num_workers=1)

testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)


net = model2.ConvNet()


Optimizer:

optimizer =  optim.Adam(net.parameters(), lr=0.001))

Loss:

loss = nn.CrossEntropyLoss()


Load Weights:

import os

if os.path.exists('nn_models/mnist_conv_trained_nn.pth'):
    checkpoint = torch.load('nn_models/mnist_conv_trained_nn.pth', map_location=torch.device(device))
    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary
    print("Model weights loaded successfully.")
else:
    t.train_network(trainloader, valloader, testloader,
                    num_classes=10, optimizer= optim.Adam(net.parameters(), lr=0.001), 
                    lfn= nn.CrossEntropyLoss(),
                    name='mnist_conv', net=net)



Result: 
Epoch:  10 Train Loss:  0.006995160548324369 Test Loss:  0.04286025067095848 Train Acc:  99.63958333333333 Test Acc:  98.95 Best Val Acc:  99.31666666666666 Best Val Loss:  0.023046843872240666 Best Test Acc:  99.04 Best Test Loss:  0.03507194934821164

