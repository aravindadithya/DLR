{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85af1c7-cc22-4007-a083-f2a298fb67bf",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93cae0-e62b-4ae4-a7a0-7a7e113b9a9d",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple 2 layer FC network on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797532-a687-49c7-b3d7-5c5545f2eeaf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1588384-18ad-4c06-83e7-cb2d7ed5a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory 1: /workspace/trained_models/MNIST/model1/nn_models/\n",
      "Model directory 3: /workspace/trained_models/MNIST/model3/nn_models/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_dir1 = os.path.join('/workspace','trained_models', 'MNIST', 'model1', 'nn_models/')\n",
    "model_dir3 = os.path.join('/workspace','trained_models', 'MNIST', 'model3', 'nn_models/')\n",
    "print(f\"Model directory 1: {model_dir1}\")\n",
    "print(f\"Model directory 3: {model_dir3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d858f4-2bd3-43a4-8f4b-88b1978ff657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import agop_fc as af\n",
    "from utils import agop_fc1 as af1\n",
    "from utils import trainer as tr\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "#import rfm\n",
    "from utils.rfm import recursive_feature_machine as rfm\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from trained_models.MNIST.model1 import trainer as t1\n",
    "from trained_models.MNIST.model3 import trainer as t3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d028bc-ee51-4fda-9f6b-206b84a1abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "#device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851228a2-b59b-41ff-bb5a-fc1af2c3f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb19e9c-acae-4eca-9cbf-6a118d45c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU (UUID: GPU-af33d267-e475-2166-48c2-2823b7ca2b60)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9856a45d-92aa-43f3-88e5-d0e413963baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/experiments/rfm_mnist'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3def1b-9d25-467e-ba0b-bfcd69fcdd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Model weights loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_285/2875907851.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_dir1+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t1.get_loaders()\n",
    "net= t1.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir1+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir1+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train network first\")\n",
    "\n",
    "#print(\"Train the network first\")\n",
    "#t1.train_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc10b5b-b461-45fe-88bc-168e9047b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.78692170818505\n"
     ]
    }
   ],
   "source": [
    "print(tr.get_acc_ce(net.to(device), testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b23854c-2ed3-4576-b498-fc5093c410ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T19:51:47.960278Z",
     "iopub.status.busy": "2025-07-09T19:51:47.959277Z",
     "iopub.status.idle": "2025-07-09T19:52:06.720453Z",
     "shell.execute_reply": "2025-07-09T19:52:06.718419Z",
     "shell.execute_reply.started": "2025-07-09T19:51:47.960278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t3.get_loaders()\n",
    "net= t3.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir3+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir3+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train the network first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87258fbe-c4b8-49d9-8319-74b5a72a4584",
   "metadata": {},
   "source": [
    "# Verify NFA for FC layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206e8d75-2d15-4529-9bdf-325264efc42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "torch.Size([3072, 3072])\n",
      "Sequential()\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 3072])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 3072])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Shape of grad matrix torch.Size([3072, 3072])\n",
      "Full Matrix Correlation Centered:  tensor(0.8155, device='cuda:0', dtype=torch.float64)\n",
      "Full Matrix Correlation Uncentered:  tensor(0.6941, device='cuda:0', dtype=torch.float64)\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.2452, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(net)\n",
    "af1.verify_NFA(net, init_net, trainloader, batch_size= 50, cutoff=10, chunk_idx=1, layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cdfd390-d9fa-4279-984b-a70d77281a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "  (1): Nonlinearity()\n",
      ")\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Full Matrix Correlation Centered:  tensor(0.7701, device='cuda:0', dtype=torch.float64)\n",
      "Full Matrix Correlation Uncentered:  tensor(0.5471, device='cuda:0', dtype=torch.float64)\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "af1.verify_NFA(net, init_net, trainloader, batch_size= 800, cutoff=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c3cb-e6fa-4e9f-b222-f1fa2845af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How to meaningfully visualise? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb970f08-c3a0-405d-8ac3-f3311e2f88f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd49e-4722-4f2d-887e-df6ad9b1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Warning: This is an extremely cpu intensive process since it uses solve function from linalg \n",
    "The rfm.py from utils is equipped with more memory efficient solvers. \n",
    "'''\n",
    "\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398c7f3-04d0-4d0e-a420-df7ce183c68a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Debug: Brute force kernel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1e641-55a8-4874-b6e3-7a93263c065a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f2150c4-24f4-4514-a748-18d616c91dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T19:52:19.901689Z",
     "iopub.status.busy": "2025-07-09T19:52:19.901689Z",
     "iopub.status.idle": "2025-07-09T19:52:19.947020Z",
     "shell.execute_reply": "2025-07-09T19:52:19.946010Z",
     "shell.execute_reply.started": "2025-07-09T19:52:19.901689Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#from numpy.linalg import solve\n",
    "from torch.linalg import solve\n",
    "import experiments.rfm_mnist.kernels as kernels #Should be called from utils\n",
    "from tqdm import tqdm\n",
    "import hickle\n",
    "import torch.distributions as distributions\n",
    "\n",
    "def laplace_kernel_M(pair1, pair2, bandwidth, M):\n",
    "    return kernels.laplacian_M(pair1, pair2, bandwidth, M)\n",
    "\n",
    "\n",
    "def get_grads(X, sol, L, P, batch_size=2):\n",
    "    torch.cuda.empty_cache()\n",
    "    M = 0.\n",
    "\n",
    "    num_samples = 10000\n",
    "    #indices = np.random.randint(len(X), size=num_samples)\n",
    "    indices = torch.randint(0, len(X), (num_samples,),device=device)\n",
    "\n",
    "    if len(X) > len(indices):\n",
    "        x = X[indices, :]\n",
    "    else:\n",
    "        x = X\n",
    "\n",
    "    K = laplace_kernel_M(X, x, L, P)\n",
    "\n",
    "    dist = kernels.euclidean_distances_M(X, x, P, squared=False)\n",
    "    \n",
    "    dist = torch.where(dist < 1e-10, torch.zeros(1,device=device).float(), dist)\n",
    "\n",
    "    K = K/dist\n",
    "    K[K == float(\"Inf\")] = 0.\n",
    "\n",
    "    #a1 = torch.from_numpy(sol.T).float()\n",
    "    a1= sol.T\n",
    "    n, d = X.shape\n",
    "    n, c = a1.shape\n",
    "    m, d = x.shape\n",
    "\n",
    "    a1 = a1.reshape(n, c, 1)\n",
    "    X1 = (X @ P).reshape(n, 1, d)\n",
    "    step1 = a1 @ X1\n",
    "    del a1, X1\n",
    "    step1 = step1.reshape(-1, c*d)\n",
    "\n",
    "    step2 = K.T @ step1\n",
    "    del step1\n",
    "\n",
    "    step2 = step2.reshape(-1, c, d)\n",
    "\n",
    "    #a2 = torch.from_numpy(sol).float()\n",
    "    a2 = sol\n",
    "    step3 = (a2 @ K).T\n",
    "\n",
    "    del K, a2\n",
    "\n",
    "    step3 = step3.reshape(m, c, 1)\n",
    "    x1 = (x @ P).reshape(m, 1, d)\n",
    "    step3 = step3 @ x1\n",
    "\n",
    "    G = (step2 - step3) * -1/L\n",
    "\n",
    "    M = 0.\n",
    "\n",
    "    bs = batch_size\n",
    "    batches = torch.split(G, bs)\n",
    "    for i in tqdm(range(len(batches))):\n",
    "        grad = batches[i].cuda()\n",
    "        gradT = torch.transpose(grad, 1, 2)\n",
    "        M += torch.sum(gradT @ grad, dim=0).cpu()\n",
    "        del grad, gradT\n",
    "    torch.cuda.empty_cache()\n",
    "    M /= len(G)\n",
    "    #M = M\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "\n",
    "def rfm(train_loader, val_loader, test_loader,\n",
    "        iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "        train_acc=True):\n",
    "\n",
    "    L = 10\n",
    "\n",
    "    X_train, y_train = get_data(train_loader)\n",
    "    X_val, y_val = get_data(val_loader)\n",
    "    X_test, y_test = get_data(test_loader)\n",
    "    \n",
    "    # Trimming: Ideally should be avoided\n",
    "    X_train, y_train = X_train[:30000], y_train[:30000]\n",
    "    X_val, y_val = X_val[:10000], y_val[:10000]\n",
    "    X_test, y_test = X_test[:10000], y_test[:10000]\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "    \n",
    "    M = torch.eye(d, dtype=torch.float32)\n",
    "    \n",
    "    '''\n",
    "    X_train= X_train.to(device)\n",
    "    y_train= y_train.to(device)\n",
    "    #X_val.to(device)\n",
    "    #y_val.to(device)\n",
    "    x_test= X_test.to(device)\n",
    "    y_test= y_test.to(device)\n",
    "    '''\n",
    "    for i in range(iters):\n",
    "        print(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        K_train = laplace_kernel_M(X_train.to(device), X_train.to(device), L, M.to(device))\n",
    "        #K_train.to(device)\n",
    "        source = (K_train + reg * torch.eye(len(K_train), device=device)).float()\n",
    "\n",
    "        \n",
    "        sol = solve(source, y_train.to(device)).T\n",
    "        sol = sol.to(device)\n",
    "        if train_acc:\n",
    "            y_pred = (sol @ K_train).T\n",
    "            #y_pred = torch.from_numpy(preds)\n",
    "            preds = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels.to(device) == preds.to(device))\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "\n",
    "        K_test = laplace_kernel_M(X_train.to(device), X_test.to(device), L, M.to(device))\n",
    "        y_pred = (sol @ K_test).T\n",
    "        #print(\"Round \" + str(i) + \" MSE: \", torch.mean(torch.square(preds - y_test.numpy())))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", F.mse_loss(y_pred.to(device), y_test.to(device)))\n",
    "        #y_pred = torch.from_numpy(preds)     \n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        preds = preds.to(device)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        labels = labels.to(device)\n",
    "        count = torch.sum(labels == preds)\n",
    "        print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "\n",
    "        M  = get_grads(X_train.to(device), sol.to(device), L, M.to(device), batch_size=batch_size)\n",
    "        print(M.shape)\n",
    "        if name is not None:\n",
    "            hickle.dump(M, 'M_' + name + '_' + str(i) + '.h')\n",
    "\n",
    "    ''''\n",
    "    W = sample_normal(M.to(device), 1024,3072)\n",
    "    print(W)\n",
    "    print(W.shape)\n",
    "    print(net.features[0].weight)\n",
    "    \n",
    "    \n",
    "    \n",
    "    K_train = laplace_kernel_M(X_train, X_train, L, torch.from_numpy(M)).numpy()\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train).T\n",
    "    K_test = laplace_kernel_M(X_train, X_test, L, torch.from_numpy(M)).numpy()\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    y_pred = torch.from_numpy(preds)\n",
    "    preds = torch.argmax(y_pred, dim=-1)\n",
    "    labels = torch.argmax(y_test, dim=-1)\n",
    "    count = torch.sum(labels == preds).numpy()\n",
    "    print(\" Final Acc: \", count / len(labels))\n",
    "    '''\n",
    "    #return mse\n",
    "\n",
    "\n",
    "def get_data(loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx, batch in enumerate(loader):\n",
    "        inputs, labels = batch\n",
    "        X.append(inputs)\n",
    "        y.append(labels)\n",
    "    return torch.cat(X, dim=0), torch.cat(y, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed2d0a59-b56b-47b7-b2a3-3bece35d39cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T19:52:23.488019Z",
     "iopub.status.busy": "2025-07-09T19:52:23.487050Z",
     "iopub.status.idle": "2025-07-09T19:52:23.496542Z",
     "shell.execute_reply": "2025-07-09T19:52:23.496542Z",
     "shell.execute_reply.started": "2025-07-09T19:52:23.488019Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_normal(covariance_matrix_M, num_rows_k, matrix_dim_t):\n",
    "   \n",
    "    # Create a mean vector of zeros, compatible with the dimensions of M\n",
    "    dtype = covariance_matrix_M.dtype\n",
    "    mean_vector = torch.zeros(matrix_dim_t, dtype=dtype, device=device)\n",
    "    mean_vector.to(device)\n",
    "    #covariance_matrix_M.to(device)\n",
    "    # Create a multivariate normal distribution object\n",
    "    # torch.distributions.MultivariateNormal expects a covariance_matrix.\n",
    "    # It internally checks for positive definiteness.\n",
    "    try:\n",
    "        mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MultivariateNormal distribution: {e}\")\n",
    "        print(\"Please ensure your covariance_matrix_M is symmetric positive definite.\")\n",
    "        # Attempt to make it PSD for robustness in example, by adding a small diagonal perturbation\n",
    "        # In a real scenario, you'd ensure your input M is correctly formed.\n",
    "        min_eigval = torch.min(torch.linalg.eigvalsh(covariance_matrix_M)).item()\n",
    "        if min_eigval <= 0:\n",
    "            print(f\"Warning: Covariance matrix has non-positive eigenvalue ({min_eigval:.2e}). Adding jitter.\")\n",
    "            covariance_matrix_M = covariance_matrix_M + torch.eye(matrix_dim_t, device=device, dtype=dtype) * (abs(min_eigval) + 1e-6)\n",
    "            mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "\n",
    "\n",
    "    # Sample num_rows_k times from the distribution\n",
    "    # The .sample() method will return a tensor of shape (num_rows_k, matrix_dim_t)\n",
    "    sampled_matrix = mvn.sample((num_rows_k,))\n",
    "\n",
    "    return sampled_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bec8406a-0bb0-46c5-bdf1-efa6471fe175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:00:46.582708Z",
     "iopub.status.busy": "2025-07-09T20:00:46.582708Z",
     "iopub.status.idle": "2025-07-09T20:00:46.590524Z",
     "shell.execute_reply": "2025-07-09T20:00:46.590524Z",
     "shell.execute_reply.started": "2025-07-09T20:00:46.582708Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.linalg import norm, svd\n",
    "def correlation(M, G):\n",
    "    A = M.clone()\n",
    "    B = G.clone()\n",
    "    A -= A.mean()\n",
    "    B -= B.mean()\n",
    "    A = A.double()\n",
    "    B = B.double()\n",
    "    normM = norm(A.flatten())\n",
    "    normG = norm(B.flatten())\n",
    "\n",
    "    corr = torch.dot(A.flatten(), B.flatten()) / (normM * normG)\n",
    "    return corr\n",
    "def cosine_similarity(vector_a, vector_b) -> float:\n",
    "  \n",
    "    # Calculate the dot product\n",
    "    dot_product = torch.dot(vector_a, vector_b)\n",
    "\n",
    "    # Calculate the Euclidean (L2) norm (magnitude) of each vector\n",
    "    norm_a = torch.linalg.norm(vector_a)\n",
    "    norm_b = torch.linalg.norm(vector_b)\n",
    "\n",
    "    # Handle cases where one or both vectors are zero vectors\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0 # Cosine similarity is undefined or typically set to 0 for zero vectors\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = dot_product / (norm_a * norm_b)\n",
    "\n",
    "    return cosine_sim\n",
    "    \n",
    "def sqrt(G):\n",
    "    U, s, Vt = svd(G)\n",
    "    s = torch.pow(s, 1./2)\n",
    "    G = U @ torch.diag(s) @ Vt\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8234842-3ac3-4786-a6cf-73c694431976",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm(trainloader, valloader, testloader, name='fc_rfm',\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0aaba271-fa28-45eb-8d17-6496e380466c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T19:54:07.518065Z",
     "iopub.status.busy": "2025-07-09T19:54:07.518065Z",
     "iopub.status.idle": "2025-07-09T19:54:07.534205Z",
     "shell.execute_reply": "2025-07-09T19:54:07.533196Z",
     "shell.execute_reply.started": "2025-07-09T19:54:07.518065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3072])\n",
      "Parameter containing:\n",
      "tensor([[-0.0164,  0.0110,  0.0087,  ...,  0.0010,  0.0019,  0.0024],\n",
      "        [-0.0033, -0.0127,  0.0155,  ...,  0.0079, -0.0117, -0.0122],\n",
      "        [-0.0145, -0.0007,  0.0079,  ..., -0.0125,  0.0094, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0080,  0.0042, -0.0011,  ..., -0.0018,  0.0047, -0.0160],\n",
      "        [-0.0113,  0.0027,  0.0152,  ...,  0.0084, -0.0130,  0.0136],\n",
      "        [-0.0171, -0.0143,  0.0057,  ..., -0.0158,  0.0157,  0.0007]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net.features[0].weight.shape)\n",
    "print(net.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28cc78e1-b6fe-49bc-b957-10c67afd2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e6f329e-fd21-4f0f-b069-94330314d27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:05:50.260605Z",
     "iopub.status.busy": "2025-07-09T20:05:50.260605Z",
     "iopub.status.idle": "2025-07-09T20:05:50.350701Z",
     "shell.execute_reply": "2025-07-09T20:05:50.349691Z",
     "shell.execute_reply.started": "2025-07-09T20:05:50.260605Z"
    }
   },
   "outputs": [],
   "source": [
    "M = hickle.load('M_fc_rfm_1.h')\n",
    "\n",
    "layer = net.features[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7055e6ba-2f77-4dab-903e-a1b5e4baf179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:05:53.465448Z",
     "iopub.status.busy": "2025-07-09T20:05:53.465448Z",
     "iopub.status.idle": "2025-07-09T20:05:53.569350Z",
     "shell.execute_reply": "2025-07-09T20:05:53.569350Z",
     "shell.execute_reply.started": "2025-07-09T20:05:53.465448Z"
    }
   },
   "outputs": [],
   "source": [
    "W= layer.T@layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1300c630-c835-4fbd-8c49-8b2b15ca42c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:05:56.835148Z",
     "iopub.status.busy": "2025-07-09T20:05:56.834148Z",
     "iopub.status.idle": "2025-07-09T20:06:01.941936Z",
     "shell.execute_reply": "2025-07-09T20:06:01.941936Z",
     "shell.execute_reply.started": "2025-07-09T20:05:56.835148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1985, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "M = sqrt(M)\n",
    "print(correlation(W,M))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efad869e-70b3-491f-8bc0-004570b1ab95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:06:05.506596Z",
     "iopub.status.busy": "2025-07-09T20:06:05.506596Z",
     "iopub.status.idle": "2025-07-09T20:06:21.835093Z",
     "shell.execute_reply": "2025-07-09T20:06:21.835093Z",
     "shell.execute_reply.started": "2025-07-09T20:06:05.506596Z"
    }
   },
   "outputs": [],
   "source": [
    "eigvals, eigvecs = torch.linalg.eig(W.to(device))\n",
    "eigvals1, eigvecs1 = torch.linalg.eig(M.to(device))\n",
    "\n",
    "#Carefu at the abs step. Though this is positive semidefnite some eigvals become negative due to approx error\n",
    "eigenvalue_magnitudes = torch.abs(eigvals)\n",
    "sorted_indices = torch.argsort(eigenvalue_magnitudes, descending= True)\n",
    "sorted_eigenvalues = eigvals[sorted_indices]\n",
    "sorted_eigenvectors = eigvecs[:, sorted_indices]\n",
    "\n",
    "eigenvalue_magnitudes1 = torch.abs(eigvals1)\n",
    "sorted_indices1 = torch.argsort(eigenvalue_magnitudes1, descending= True)\n",
    "sorted_eigenvalues1 = eigvals[sorted_indices1]\n",
    "sorted_eigenvectors1 = eigvecs[:, sorted_indices1]\n",
    "\n",
    "\n",
    "\n",
    "# For Psd this guarantees vectors sorted in ascending order\n",
    "#eigvals, eigvecs = torch.linalg.eigh(W.to(device))\n",
    "#eigvals1, eigvecs1 = torch.linalg.eigh(M.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa7a0941-2cd3-4f40-935a-bc2f452f5457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T20:06:27.430786Z",
     "iopub.status.busy": "2025-07-09T20:06:27.429787Z",
     "iopub.status.idle": "2025-07-09T20:06:27.448060Z",
     "shell.execute_reply": "2025-07-09T20:06:27.446541Z",
     "shell.execute_reply.started": "2025-07-09T20:06:27.430786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0135-0.0057j, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sorted_eigenvectors[0], sorted_eigenvectors1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8d056-ec80-4037-be3e-b668373ef284",
   "metadata": {},
   "outputs": [],
   "source": [
    "WS = sample_normal(M.to(device), 1024,3072)\n",
    "#compare_matrices_svd(WS.to(device), layer.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f10d4-71bb-4888-9726-a6370730b751",
   "metadata": {},
   "source": [
    "# Debug: Rfm utils code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec30cab-538c-47c6-b0f8-959b1e4d28a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m rfm\u001b[38;5;241m.\u001b[39mLaplaceRFM(bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, mem_gb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      2\u001b[0m                        centering\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, p_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bandwidth_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model = rfm.GeneralizedLaplaceRFM(bandwidth=1., exponent=1., agop_power=0.5, mem_gb=15, \u001b[39;00m\n\u001b[1;32m      5\u001b[0m                                   \u001b[38;5;66;03m#centering=True, reg=1e-3, iters=5, p_batch_size=None, bandwidth_mode='constant')\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m Ms, mses \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrainloader\u001b[49m, testloader, iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenpro\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m             classification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, M_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     12\u001b[0m             class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_best_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     13\u001b[0m             return_Ms\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, lr_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, total_points_to_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, \n\u001b[1;32m     14\u001b[0m             solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolve\u001b[39m\u001b[38;5;124m'\u001b[39m, fit_last_M\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, prefit_eigenpro\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mmodel.fit(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        trainloader, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    ) \u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "model = rfm.LaplaceRFM(bandwidth=1., diag=False, device=device, mem_gb=3, \n",
    "                       centering=True, reg=1e-3, iters=10, p_batch_size=None, bandwidth_mode='constant')\n",
    "\n",
    "#model = rfm.GeneralizedLaplaceRFM(bandwidth=1., exponent=1., agop_power=0.5, mem_gb=15, \n",
    "                                  #centering=True, reg=1e-3, iters=5, p_batch_size=None, bandwidth_mode='constant')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ms, mses = model.fit(trainloader, testloader, iters=3, method='eigenpro', \n",
    "            classification=True, verbose=True, M_batch_size=None, \n",
    "            class_weight=None, return_best_params=True, bs=None, \n",
    "            return_Ms= True, lr_scale=1, total_points_to_sample=10000, \n",
    "            solver='solve', fit_last_M= True, prefit_eigenpro=True, epochs=2)\n",
    "\n",
    "'''\n",
    "model.fit(\n",
    "        trainloader, \n",
    "        testloader, \n",
    "        method='eigenpro', epochs=2, print_every=1,\n",
    "        iters=3,\n",
    "        classif=False\n",
    "    ) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca08077-be29-4f06-973f-aa5b41be364c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
