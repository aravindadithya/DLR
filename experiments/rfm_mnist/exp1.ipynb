{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85af1c7-cc22-4007-a083-f2a298fb67bf",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93cae0-e62b-4ae4-a7a0-7a7e113b9a9d",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple 2 layer FC network on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797532-a687-49c7-b3d7-5c5545f2eeaf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1588384-18ad-4c06-83e7-cb2d7ed5a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garav\\AGOP\\DLR\\experiments\\rfm_mnist\n",
      "Parent directory: C:\\Users\\garav\\AGOP\\DLR\n",
      "Model directory 1: C:\\Users\\garav\\AGOP\\DLR\\trained_models\\MNIST\\model1\\nn_models\\\n",
      "Model directory 3: C:\\Users\\garav\\AGOP\\DLR\\trained_models\\MNIST\\model3\\nn_models\\\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "model_dir1 = os.path.join(parent_dir, 'trained_models', 'MNIST', 'model1', 'nn_models\\\\')\n",
    "model_dir3 = os.path.join(parent_dir, 'trained_models', 'MNIST', 'model3', 'nn_models\\\\')\n",
    "\n",
    "'''\n",
    "parent_dir='C:\\\\Users\\\\garav\\\\AGOP\\\\DLR'\n",
    "model_dir1= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model1\\\\nn_models\\\\'\n",
    "model_dir3= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model3\\\\nn_models\\\\'\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "'''\n",
    "sys.path.append(parent_dir)\n",
    "print(f\"Parent directory: {parent_dir}\")\n",
    "print(f\"Model directory 1: {model_dir1}\")\n",
    "print(f\"Model directory 3: {model_dir3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d858f4-2bd3-43a4-8f4b-88b1978ff657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garav\\AGOP\\DLR\\experiments\\rfm_mnist\n",
      "C:\\Users\\garav\\AGOP\\DLR\n",
      "C:\\Users\\garav\\AGOP\\DLR\\trained_models\\MNIST\\model1\\nn_models\\\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import agop_fc as af\n",
    "from utils import agop_fc1 as af1\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import rfm\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from trained_models.MNIST.model1 import trainer as t1\n",
    "from trained_models.MNIST.model3 import trainer as t3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d028bc-ee51-4fda-9f6b-206b84a1abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851228a2-b59b-41ff-bb5a-fc1af2c3f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3def1b-9d25-467e-ba0b-bfcd69fcdd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t1.get_loaders()\n",
    "net= t1.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir1+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir1+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train network first\")\n",
    "\n",
    "#print(\"Train the network first\")\n",
    "#t1.train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5b23854c-2ed3-4576-b498-fc5093c410ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Train the network first\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t3.get_loaders()\n",
    "net= t3.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir3+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir3+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train the network first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87258fbe-c4b8-49d9-8319-74b5a72a4584",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Verify NFA for FC layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206e8d75-2d15-4529-9bdf-325264efc42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0')\n",
      "Computing GOP for sample 0 out of 50\n",
      "Computing GOP for sample 1 out of 50\n",
      "Computing GOP for sample 2 out of 50\n",
      "Computing GOP for sample 3 out of 50\n",
      "Computing GOP for sample 4 out of 50\n",
      "Computing GOP for sample 5 out of 50\n",
      "Computing GOP for sample 6 out of 50\n",
      "Computing GOP for sample 7 out of 50\n",
      "Computing GOP for sample 8 out of 50\n",
      "Computing GOP for sample 9 out of 50\n",
      "Computing GOP for sample 10 out of 50\n",
      "Computing GOP for sample 11 out of 50\n",
      "Computing GOP for sample 12 out of 50\n",
      "Computing GOP for sample 13 out of 50\n",
      "Computing GOP for sample 14 out of 50\n",
      "Computing GOP for sample 15 out of 50\n",
      "Computing GOP for sample 16 out of 50\n",
      "Computing GOP for sample 17 out of 50\n",
      "Computing GOP for sample 18 out of 50\n",
      "Computing GOP for sample 19 out of 50\n",
      "Computing GOP for sample 20 out of 50\n",
      "Computing GOP for sample 21 out of 50\n",
      "Computing GOP for sample 22 out of 50\n",
      "Computing GOP for sample 23 out of 50\n",
      "Computing GOP for sample 24 out of 50\n",
      "Computing GOP for sample 25 out of 50\n",
      "Computing GOP for sample 26 out of 50\n",
      "Computing GOP for sample 27 out of 50\n",
      "Computing GOP for sample 28 out of 50\n",
      "Computing GOP for sample 29 out of 50\n",
      "Computing GOP for sample 30 out of 50\n",
      "Computing GOP for sample 31 out of 50\n",
      "Computing GOP for sample 32 out of 50\n",
      "Computing GOP for sample 33 out of 50\n",
      "Computing GOP for sample 34 out of 50\n",
      "Computing GOP for sample 35 out of 50\n",
      "Computing GOP for sample 36 out of 50\n",
      "Computing GOP for sample 37 out of 50\n",
      "Computing GOP for sample 38 out of 50\n",
      "Computing GOP for sample 39 out of 50\n",
      "Computing GOP for sample 40 out of 50\n",
      "Computing GOP for sample 41 out of 50\n",
      "Computing GOP for sample 42 out of 50\n",
      "Computing GOP for sample 43 out of 50\n",
      "Computing GOP for sample 44 out of 50\n",
      "Computing GOP for sample 45 out of 50\n",
      "Computing GOP for sample 46 out of 50\n",
      "Computing GOP for sample 47 out of 50\n",
      "Computing GOP for sample 48 out of 50\n",
      "Computing GOP for sample 49 out of 50\n",
      "Computing GOP for sample 50 out of 50\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Correlation between Trained CNFM and AGOP:  tensor(0.5470, device='cuda:0')\n",
      "Final:  tensor(0.4899, device='cuda:0') tensor(0.5470, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1521,  0.0036,  0.0123,  ..., -0.0081, -0.0019,  0.0023],\n",
       "        [ 0.0036,  0.1669, -0.0310,  ...,  0.0210, -0.0045,  0.0172],\n",
       "        [ 0.0123, -0.0310,  0.1918,  ..., -0.0199, -0.0021, -0.0093],\n",
       "        ...,\n",
       "        [-0.0081,  0.0210, -0.0199,  ...,  0.1433,  0.0097,  0.0215],\n",
       "        [-0.0019, -0.0045, -0.0021,  ...,  0.0097,  0.1614,  0.0088],\n",
       "        [ 0.0023,  0.0172, -0.0093,  ...,  0.0215,  0.0088,  0.1550]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(net)\n",
    "af.verify_NFA(net, init_net, trainloader, max_batch= 50, classes=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdfd390-d9fa-4279-984b-a70d77281a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0', dtype=torch.float64)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "  (1): Nonlinearity()\n",
      ")\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Full Matrix Correlation Centered:  tensor(0.7705, device='cuda:0', dtype=torch.float64)\n",
      "Full Matrix Correlation Uncentered:  tensor(0.5471, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "af1.verify_NFA(net, init_net, trainloader, batch_size= 800, cutoff=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c3cb-e6fa-4e9f-b222-f1fa2845af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How to meaningfully visualise? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb970f08-c3a0-405d-8ac3-f3311e2f88f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd49e-4722-4f2d-887e-df6ad9b1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Warning: This is an extremely cpu intensive process since it uses solve function from linalg \n",
    "The rfm.py from utils is equipped with more memory efficient solvers. \n",
    "'''\n",
    "\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398c7f3-04d0-4d0e-a420-df7ce183c68a",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1f2150c4-24f4-4514-a748-18d616c91dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#from numpy.linalg import solve\n",
    "from torch.linalg import solve\n",
    "import kernels #Should be called from utils\n",
    "from tqdm import tqdm\n",
    "import hickle\n",
    "import torch.distributions as distributions\n",
    "\n",
    "def laplace_kernel_M(pair1, pair2, bandwidth, M):\n",
    "    return kernels.laplacian_M(pair1, pair2, bandwidth, M)\n",
    "\n",
    "\n",
    "def get_grads(X, sol, L, P, batch_size=2):\n",
    "    M = 0.\n",
    "\n",
    "    num_samples = 10000\n",
    "    #indices = np.random.randint(len(X), size=num_samples)\n",
    "    indices = torch.randint(0, len(X), (num_samples,))\n",
    "\n",
    "    if len(X) > len(indices):\n",
    "        x = X[indices, :]\n",
    "    else:\n",
    "        x = X\n",
    "\n",
    "    K = laplace_kernel_M(X, x, L, P)\n",
    "\n",
    "    dist = kernels.euclidean_distances_M(X, x, P, squared=False)\n",
    "    dist = torch.where(dist < 1e-10, torch.zeros(1).float(), dist)\n",
    "\n",
    "    K = K/dist\n",
    "    K[K == float(\"Inf\")] = 0.\n",
    "\n",
    "    #a1 = torch.from_numpy(sol.T).float()\n",
    "    a1= sol.T\n",
    "    n, d = X.shape\n",
    "    n, c = a1.shape\n",
    "    m, d = x.shape\n",
    "\n",
    "    a1 = a1.reshape(n, c, 1)\n",
    "    X1 = (X @ P).reshape(n, 1, d)\n",
    "    step1 = a1 @ X1\n",
    "    del a1, X1\n",
    "    step1 = step1.reshape(-1, c*d)\n",
    "\n",
    "    step2 = K.T @ step1\n",
    "    del step1\n",
    "\n",
    "    step2 = step2.reshape(-1, c, d)\n",
    "\n",
    "    #a2 = torch.from_numpy(sol).float()\n",
    "    a2 = sol\n",
    "    step3 = (a2 @ K).T\n",
    "\n",
    "    del K, a2\n",
    "\n",
    "    step3 = step3.reshape(m, c, 1)\n",
    "    x1 = (x @ P).reshape(m, 1, d)\n",
    "    step3 = step3 @ x1\n",
    "\n",
    "    G = (step2 - step3) * -1/L\n",
    "\n",
    "    M = 0.\n",
    "\n",
    "    bs = batch_size\n",
    "    batches = torch.split(G, bs)\n",
    "    for i in tqdm(range(len(batches))):\n",
    "        grad = batches[i].cuda()\n",
    "        gradT = torch.transpose(grad, 1, 2)\n",
    "        M += torch.sum(gradT @ grad, dim=0).cpu()\n",
    "        del grad, gradT\n",
    "    torch.cuda.empty_cache()\n",
    "    M /= len(G)\n",
    "    #M = M\n",
    "\n",
    "    return M\n",
    "\n",
    "def sample_normal(covariance_matrix_M, num_rows_k, matrix_dim_t):\n",
    "   \n",
    "    # Create a mean vector of zeros, compatible with the dimensions of M\n",
    "    dtype = covariance_matrix_M.dtype\n",
    "    mean_vector = torch.zeros(matrix_dim_t, dtype=dtype, device=device)\n",
    "    mean_vector.to(device)\n",
    "    #covariance_matrix_M.to(device)\n",
    "    # Create a multivariate normal distribution object\n",
    "    # torch.distributions.MultivariateNormal expects a covariance_matrix.\n",
    "    # It internally checks for positive definiteness.\n",
    "    try:\n",
    "        mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MultivariateNormal distribution: {e}\")\n",
    "        print(\"Please ensure your covariance_matrix_M is symmetric positive definite.\")\n",
    "        # Attempt to make it PSD for robustness in example, by adding a small diagonal perturbation\n",
    "        # In a real scenario, you'd ensure your input M is correctly formed.\n",
    "        min_eigval = torch.min(torch.linalg.eigvalsh(covariance_matrix_M)).item()\n",
    "        if min_eigval <= 0:\n",
    "            print(f\"Warning: Covariance matrix has non-positive eigenvalue ({min_eigval:.2e}). Adding jitter.\")\n",
    "            covariance_matrix_M = covariance_matrix_M + torch.eye(matrix_dim_t, device=device, dtype=dtype) * (abs(min_eigval) + 1e-6)\n",
    "            mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "\n",
    "\n",
    "    # Sample num_rows_k times from the distribution\n",
    "    # The .sample() method will return a tensor of shape (num_rows_k, matrix_dim_t)\n",
    "    sampled_matrix = mvn.sample((num_rows_k,))\n",
    "\n",
    "    return sampled_matrix\n",
    "\n",
    "def rfm(train_loader, val_loader, test_loader,\n",
    "        iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "        train_acc=True):\n",
    "\n",
    "    L = 10\n",
    "\n",
    "    X_train, y_train = get_data(train_loader)\n",
    "    X_val, y_val = get_data(val_loader)\n",
    "    X_test, y_test = get_data(test_loader)\n",
    "\n",
    "    # Trimming: Ideally should be avoided\n",
    "    X_train, y_train = X_train[:10000], y_train[:10000]\n",
    "    X_val, y_val = X_val[:10000], y_val[:10000]\n",
    "    X_test, y_test = X_test[:1000], y_test[:1000]\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "\n",
    "    M = torch.eye(d, dtype=torch.float32)\n",
    "    M.to(device)\n",
    "\n",
    "    for i in range(iters):\n",
    "        K_train = laplace_kernel_M(X_train, X_train, L, M)\n",
    "        K_train.to(device)\n",
    "        y_train.to(device)\n",
    "        #Todo: Does the below line use cpu or gpu escpecially the identity matrix.\n",
    "        source = (K_train + reg * torch.eye(len(K_train))).float()\n",
    "        sol = solve(source, y_train).T\n",
    "\n",
    "        if train_acc:\n",
    "            y_pred = (sol @ K_train).T\n",
    "            #y_pred = torch.from_numpy(preds)\n",
    "            preds = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds)\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "\n",
    "        K_test = laplace_kernel_M(X_train, X_test, L, M)\n",
    "        y_pred = (sol @ K_test).T\n",
    "        #print(\"Round \" + str(i) + \" MSE: \", torch.mean(torch.square(preds - y_test.numpy())))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", F.mse_loss(y_pred, y_test))\n",
    "        #y_pred = torch.from_numpy(preds)     \n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        count = torch.sum(labels == preds)\n",
    "        print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "\n",
    "        M  = get_grads(X_train, sol, L, M, batch_size=batch_size)\n",
    "        print(M.shape)\n",
    "        if name is not None:\n",
    "            hickle.dump(M, 'M_' + name + '_' + str(i) + '.h')\n",
    "    W = sample_normal(M.to(device), 1024,3072)\n",
    "    print(W)\n",
    "    print(W.shape)\n",
    "    print(net.features[0].weight)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    K_train = laplace_kernel_M(X_train, X_train, L, torch.from_numpy(M)).numpy()\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train).T\n",
    "    K_test = laplace_kernel_M(X_train, X_test, L, torch.from_numpy(M)).numpy()\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    y_pred = torch.from_numpy(preds)\n",
    "    preds = torch.argmax(y_pred, dim=-1)\n",
    "    labels = torch.argmax(y_test, dim=-1)\n",
    "    count = torch.sum(labels == preds).numpy()\n",
    "    print(\" Final Acc: \", count / len(labels))\n",
    "    '''\n",
    "    #return mse\n",
    "\n",
    "\n",
    "def get_data(loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx, batch in enumerate(loader):\n",
    "        inputs, labels = batch\n",
    "        X.append(inputs)\n",
    "        y.append(labels)\n",
    "    return torch.cat(X, dim=0), torch.cat(y, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f8234842-3ac3-4786-a6cf-73c694431976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 Train Acc:  tensor(1.)\n",
      "Round 0 MSE:  tensor(0.0050)\n",
      "Round 0 Acc:  tensor(0.9930)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:26<00:00, 37.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072])\n",
      "Round 1 Train Acc:  tensor(1.)\n",
      "Round 1 MSE:  tensor(0.0036)\n",
      "Round 1 Acc:  tensor(0.9920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072])\n",
      "Round 2 Train Acc:  tensor(1.)\n",
      "Round 2 MSE:  tensor(0.0035)\n",
      "Round 2 Acc:  tensor(0.9900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072])\n",
      "Error creating MultivariateNormal distribution: Expected parameter covariance_matrix (Tensor of shape (3072, 3072)) of distribution MultivariateNormal(loc: torch.Size([3072]), covariance_matrix: torch.Size([3072, 3072])) to satisfy the constraint PositiveDefinite(), but found invalid values:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Please ensure your covariance_matrix_M is symmetric positive definite.\n",
      "Warning: Covariance matrix has non-positive eigenvalue (-1.92e-09). Adding jitter.\n",
      "tensor([[-8.2440e-04, -1.7557e-03, -3.9388e-04,  ..., -8.2440e-04,\n",
      "         -2.1043e-03, -5.1755e-04],\n",
      "        [ 7.3327e-04, -7.8361e-04,  9.7317e-04,  ..., -1.4617e-04,\n",
      "         -3.7461e-04, -7.0244e-04],\n",
      "        [-7.0590e-06,  1.5303e-03,  1.6631e-04,  ...,  1.4548e-03,\n",
      "          8.2789e-04, -3.1883e-04],\n",
      "        ...,\n",
      "        [-7.1151e-04,  5.2996e-04,  3.9424e-04,  ...,  1.1444e-03,\n",
      "          6.6135e-04,  1.2885e-03],\n",
      "        [ 7.2751e-04, -3.1571e-04, -1.2555e-03,  ..., -4.1963e-04,\n",
      "          1.9311e-03,  4.7199e-04],\n",
      "        [ 2.0682e-03,  1.2423e-03, -3.3692e-04,  ..., -5.8769e-04,\n",
      "          6.4057e-04,  1.5189e-03]], device='cuda:0')\n",
      "torch.Size([1024, 3072])\n",
      "Parameter containing:\n",
      "tensor([[-0.0164,  0.0110,  0.0087,  ...,  0.0010,  0.0019,  0.0024],\n",
      "        [-0.0033, -0.0127,  0.0155,  ...,  0.0079, -0.0117, -0.0122],\n",
      "        [-0.0145, -0.0007,  0.0079,  ..., -0.0125,  0.0094, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0080,  0.0042, -0.0011,  ..., -0.0018,  0.0047, -0.0160],\n",
      "        [-0.0113,  0.0027,  0.0152,  ...,  0.0084, -0.0130,  0.0136],\n",
      "        [-0.0171, -0.0143,  0.0057,  ..., -0.0158,  0.0157,  0.0007]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "rfm(trainloader, valloader, testloader, name=None,\n",
    "            batch_size=10, iters=3, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0aaba271-fa28-45eb-8d17-6496e380466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3072])\n",
      "Parameter containing:\n",
      "tensor([[-0.0164,  0.0110,  0.0087,  ...,  0.0010,  0.0019,  0.0024],\n",
      "        [-0.0033, -0.0127,  0.0155,  ...,  0.0079, -0.0117, -0.0122],\n",
      "        [-0.0145, -0.0007,  0.0079,  ..., -0.0125,  0.0094, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0080,  0.0042, -0.0011,  ..., -0.0018,  0.0047, -0.0160],\n",
      "        [-0.0113,  0.0027,  0.0152,  ...,  0.0084, -0.0130,  0.0136],\n",
      "        [-0.0171, -0.0143,  0.0057,  ..., -0.0158,  0.0157,  0.0007]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net.features[0].weight.shape)\n",
    "print(net.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28cc78e1-b6fe-49bc-b957-10c67afd2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f329e-fd21-4f0f-b069-94330314d27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
