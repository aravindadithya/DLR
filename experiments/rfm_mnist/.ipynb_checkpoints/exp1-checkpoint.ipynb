{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85af1c7-cc22-4007-a083-f2a298fb67bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93cae0-e62b-4ae4-a7a0-7a7e113b9a9d",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple 2 layer FC network on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797532-a687-49c7-b3d7-5c5545f2eeaf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1588384-18ad-4c06-83e7-cb2d7ed5a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parent_dir='C:\\\\Users\\\\garav\\\\AGOP\\\\DLR'\n",
    "model_dir1= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model1\\\\nn_models\\\\'\n",
    "model_dir3= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model3\\\\nn_models\\\\'\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d858f4-2bd3-43a4-8f4b-88b1978ff657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import agop_fc as af\n",
    "from utils import agop_fc1 as af1\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import rfm\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from trained_models.MNIST.model1 import trainer as t1\n",
    "from trained_models.MNIST.model3 import trainer as t3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d028bc-ee51-4fda-9f6b-206b84a1abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851228a2-b59b-41ff-bb5a-fc1af2c3f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3def1b-9d25-467e-ba0b-bfcd69fcdd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t1.get_loaders()\n",
    "net= t1.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir1+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir1+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "\n",
    "#print(\"Train the network first\")\n",
    "#t1.train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23854c-2ed3-4576-b498-fc5093c410ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader, testloader = t3.get_loaders()\n",
    "net= t3.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir3+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir3+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train the network first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87258fbe-c4b8-49d9-8319-74b5a72a4584",
   "metadata": {},
   "source": [
    "# Verify NFA for FC layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206e8d75-2d15-4529-9bdf-325264efc42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0')\n",
      "Computing GOP for sample 0 out of 50\n",
      "Computing GOP for sample 1 out of 50\n",
      "Computing GOP for sample 2 out of 50\n",
      "Computing GOP for sample 3 out of 50\n",
      "Computing GOP for sample 4 out of 50\n",
      "Computing GOP for sample 5 out of 50\n",
      "Computing GOP for sample 6 out of 50\n",
      "Computing GOP for sample 7 out of 50\n",
      "Computing GOP for sample 8 out of 50\n",
      "Computing GOP for sample 9 out of 50\n",
      "Computing GOP for sample 10 out of 50\n",
      "Computing GOP for sample 11 out of 50\n",
      "Computing GOP for sample 12 out of 50\n",
      "Computing GOP for sample 13 out of 50\n",
      "Computing GOP for sample 14 out of 50\n",
      "Computing GOP for sample 15 out of 50\n",
      "Computing GOP for sample 16 out of 50\n",
      "Computing GOP for sample 17 out of 50\n",
      "Computing GOP for sample 18 out of 50\n",
      "Computing GOP for sample 19 out of 50\n",
      "Computing GOP for sample 20 out of 50\n",
      "Computing GOP for sample 21 out of 50\n",
      "Computing GOP for sample 22 out of 50\n",
      "Computing GOP for sample 23 out of 50\n",
      "Computing GOP for sample 24 out of 50\n",
      "Computing GOP for sample 25 out of 50\n",
      "Computing GOP for sample 26 out of 50\n",
      "Computing GOP for sample 27 out of 50\n",
      "Computing GOP for sample 28 out of 50\n",
      "Computing GOP for sample 29 out of 50\n",
      "Computing GOP for sample 30 out of 50\n",
      "Computing GOP for sample 31 out of 50\n",
      "Computing GOP for sample 32 out of 50\n",
      "Computing GOP for sample 33 out of 50\n",
      "Computing GOP for sample 34 out of 50\n",
      "Computing GOP for sample 35 out of 50\n",
      "Computing GOP for sample 36 out of 50\n",
      "Computing GOP for sample 37 out of 50\n",
      "Computing GOP for sample 38 out of 50\n",
      "Computing GOP for sample 39 out of 50\n",
      "Computing GOP for sample 40 out of 50\n",
      "Computing GOP for sample 41 out of 50\n",
      "Computing GOP for sample 42 out of 50\n",
      "Computing GOP for sample 43 out of 50\n",
      "Computing GOP for sample 44 out of 50\n",
      "Computing GOP for sample 45 out of 50\n",
      "Computing GOP for sample 46 out of 50\n",
      "Computing GOP for sample 47 out of 50\n",
      "Computing GOP for sample 48 out of 50\n",
      "Computing GOP for sample 49 out of 50\n",
      "Computing GOP for sample 50 out of 50\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Correlation between Trained CNFM and AGOP:  tensor(0.5470, device='cuda:0')\n",
      "Final:  tensor(0.4899, device='cuda:0') tensor(0.5470, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1521,  0.0036,  0.0123,  ..., -0.0081, -0.0019,  0.0023],\n",
       "        [ 0.0036,  0.1669, -0.0310,  ...,  0.0210, -0.0045,  0.0172],\n",
       "        [ 0.0123, -0.0310,  0.1918,  ..., -0.0199, -0.0021, -0.0093],\n",
       "        ...,\n",
       "        [-0.0081,  0.0210, -0.0199,  ...,  0.1433,  0.0097,  0.0215],\n",
       "        [-0.0019, -0.0045, -0.0021,  ...,  0.0097,  0.1614,  0.0088],\n",
       "        [ 0.0023,  0.0172, -0.0093,  ...,  0.0215,  0.0088,  0.1550]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(net)\n",
    "af.verify_NFA(net, init_net, trainloader, max_batch= 50, classes=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdfd390-d9fa-4279-984b-a70d77281a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0', dtype=torch.float64)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "  (1): Nonlinearity()\n",
      ")\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Full Matrix Correlation Centered:  tensor(0.7705, device='cuda:0', dtype=torch.float64)\n",
      "Full Matrix Correlation Uncentered:  tensor(0.5471, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "af1.verify_NFA(net, init_net, trainloader, batch_size= 800, cutoff=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c3cb-e6fa-4e9f-b222-f1fa2845af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How to meaningfully visualise? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb970f08-c3a0-405d-8ac3-f3311e2f88f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd49e-4722-4f2d-887e-df6ad9b1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Warning: This is an extremely cpu intensive process since it uses solve function from linalg \n",
    "The rfm.py from utils is equipped with more memory efficient solvers. \n",
    "'''\n",
    "\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c26017-64bb-4682-8271-a349255271c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
