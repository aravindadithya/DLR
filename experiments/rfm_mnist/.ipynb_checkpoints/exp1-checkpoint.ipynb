{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85af1c7-cc22-4007-a083-f2a298fb67bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93cae0-e62b-4ae4-a7a0-7a7e113b9a9d",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple 2 layer FC network on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797532-a687-49c7-b3d7-5c5545f2eeaf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1588384-18ad-4c06-83e7-cb2d7ed5a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parent_dir='C:\\\\Users\\\\garav\\\\AGOP\\\\DLR'\n",
    "model_dir= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model3\\\\nn_models\\\\'\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d858f4-2bd3-43a4-8f4b-88b1978ff657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import trainer as t\n",
    "from utils import agop_fc as af\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import rfm\n",
    "import numpy as np\n",
    "from trained_models.MNIST.model3 import model3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d028bc-ee51-4fda-9f6b-206b84a1abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ac3bb17-df96-4419-884c-4d94e643f13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\experiments\\\\rfm_mnist'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a34574-02da-41c8-a643-f23e872e89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_data(dataset, num_samples=-1):\n",
    "    labelset = {}\n",
    "    for i in range(10):\n",
    "        one_hot = torch.zeros(10)\n",
    "        one_hot[i] = 1\n",
    "        labelset[i] = one_hot\n",
    "\n",
    "    subset = [(ex.flatten(), labelset[label]) for \\\n",
    "              idx, (ex, label) in enumerate(dataset) if idx < num_samples]\n",
    "    return subset\n",
    "\n",
    "\n",
    "def group_by_class(dataset):\n",
    "    labelset = {}\n",
    "    for i in range(10):\n",
    "        labelset[i] = []\n",
    "    for i, batch in enumerate(dataset):\n",
    "        img, label = batch\n",
    "        labelset[label].append(img.view(1, 3, 32, 32))\n",
    "    return labelset\n",
    "\n",
    "\n",
    "def split(trainset, p=.8):\n",
    "    train, val = train_test_split(trainset, train_size=p)\n",
    "    return train, val\n",
    "\n",
    "def merge_data(mnist, n):\n",
    "    #cifar_by_label = group_by_class(cifar)\n",
    "\n",
    "    mnist_by_label = group_by_class(mnist)\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    labelset = {}\n",
    "\n",
    "    for i in range(10):\n",
    "        one_hot = torch.zeros(1, 10)\n",
    "        one_hot[0, i] = 1\n",
    "        labelset[i] = one_hot\n",
    "\n",
    "    for l in mnist_by_label:\n",
    "\n",
    "        #cifar_data = torch.cat(cifar_by_label[l])\n",
    "        mnist_data = torch.cat(mnist_by_label[l])\n",
    "        min_len = len(mnist_data)\n",
    "        m = min(n, min_len)\n",
    "        #cifar_data = cifar_data[:m]\n",
    "        mnist_data = mnist_data[:m]\n",
    "\n",
    "        merged = torch.cat([mnist_data], axis=-1)\n",
    "        #for i in range(3):\n",
    "           # vis.image(merged[i])\n",
    "        data.append(merged.reshape(m, -1))\n",
    "        print(merged.shape)\n",
    "        labels.append(np.repeat(labelset[l], m, axis=0))\n",
    "    data = torch.cat(data, axis=0)\n",
    "\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    merged_labels = torch.from_numpy(labels)\n",
    "\n",
    "    return list(zip(data, labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851228a2-b59b-41ff-bb5a-fc1af2c3f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d89618-c570-4f80-aa38-3b468e076440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEED = 5700\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "#cudnn.benchmark = False\n",
    "\n",
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "def repeat_channel(x):\n",
    "    return x.repeat(3, 1, 1)\n",
    "\n",
    "mnist_transform = transforms.Compose(\n",
    "    [transforms.Resize([32, 32]),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Lambda(repeat_channel)]\n",
    ")\n",
    "\n",
    "path= './data'  \n",
    "    \n",
    "mnist_trainset = torchvision.datasets.MNIST(root=path,\n",
    "                                                train=True,\n",
    "                                                transform=mnist_transform,\n",
    "                                                download=True)\n",
    "\n",
    "#trainset = group_by_class(mnist_trainset)\n",
    "trainset = merge_data(mnist_trainset, 5000)\n",
    "trainset, valset = split(trainset, p=.8)\n",
    "print(\"Train Size: \", len(trainset), \"Val Size: \", len(valset))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=100,\n",
    "                                            shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "mnist_testset = torchvision.datasets.MNIST(root=path,\n",
    "                                               train=False,\n",
    "                                               transform=mnist_transform,\n",
    "                                               download=True)\n",
    "\n",
    "print(\"Test Size: \", len(mnist_testset))\n",
    "testset = merge_data(mnist_testset, 900)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "name = 'mnist_fc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbaa2e5-f13d-4147-b450-a54773243222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(trainloader):\n",
    "        inputs, labels = batch\n",
    "        _, dim = inputs.shape\n",
    "        break\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ed0b5d-83af-40b0-870a-286a22512905",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model3.Net(3072, num_classes=10)\n",
    "init_net=deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9297bf74-13ae-452d-80fd-086724102a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(model_dir+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    t.train_network(trainloader, valloader, testloader,\n",
    "                num_classes=10, root_path= model_dir, \n",
    "                optimizer=torch.optim.SGD(net.parameters(), lr=.1),\n",
    "                lfn=  nn.MSELoss(), \n",
    "                num_epochs = 10,\n",
    "                name=name, net=net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339db119-96d3-496f-8f2a-5064a96b8660",
   "metadata": {},
   "source": [
    "# AGOP_FC.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9a58937-1b9c-4823-9f76-630c56997763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "''' This module does the following\n",
    "1. Scan the network for conv layers\n",
    "2. For each FC layer compute W^TW of eq 3\n",
    "3. For each FC layer compute the AGOP(AJOP in case of multiple outputs)\n",
    "4. For each conv layer print the pearson correlation between 2 and 3\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "#from functorch import jacrev, vmap\n",
    "from torch.func import jacrev\n",
    "from torch.nn.functional import pad\n",
    "#import dataset\n",
    "from numpy.linalg import eig\n",
    "from copy import deepcopy\n",
    "from torch.linalg import norm, svd\n",
    "from torchvision import models\n",
    "import visdom\n",
    "from torch.linalg import norm, eig\n",
    "\n",
    "\n",
    "SEED = 2323\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "vis = visdom.Visdom('http://127.0.0.1', use_incoming_socket=False)\n",
    "vis.close(env='main')\n",
    "\n",
    "def get_jacobian(net, data, c_idx=0, chunk=100):\n",
    "    with torch.no_grad():\n",
    "        def single_net(x):\n",
    "            # x is (s)\n",
    "            return net(x.unsqueeze(0))[:,c_idx*chunk:(c_idx+1)*chunk].squeeze(0)\n",
    "        # Parallelize across the images.\n",
    "        return torch.vmap(jacrev(single_net))(data) #(n,chunk,s)\n",
    "\n",
    "def min_max(M):\n",
    "    return (M - M.min()) / (M.max() - M.min())\n",
    "\n",
    "def sqrt(G):\n",
    "    U, s, Vt = svd(G)\n",
    "    s = torch.pow(s, 1./2)\n",
    "    G = U @ torch.diag(s) @ Vt\n",
    "    return G\n",
    "\n",
    "\n",
    "def correlation(M1, M2):\n",
    "    M1 -= M1.mean()\n",
    "    M2 -= M2.mean()\n",
    "\n",
    "    norm1 = norm(M1.flatten())\n",
    "    norm2 = norm(M2.flatten())\n",
    "\n",
    "    return torch.sum(M1.cuda() * M2.cuda()) / (norm1 * norm2)\n",
    "\n",
    "def egop(model, z, c=10, chunk_idxs=1):\n",
    "    ajop = 0\n",
    "    #Chunking is done to compute jacobian as chunks. This saves memory\n",
    "    chunk = c // chunk_idxs\n",
    "    for i in range(chunk_idxs):\n",
    "        grads = get_jacobian(model, z, c_idx=i, chunk=chunk) #(n,chunk,s)\n",
    "        grads_t = grads.transpose(1, 2) \n",
    "        ajop_matmul= torch.matmul(grads_t, grads) #(n,s,s)\n",
    "        #Clarify: mean and sum are making no difference here. Check if trainloader has grouped images\n",
    "        ajop += torch.mean(ajop_matmul, dim=0) #(s,s)\n",
    "    return ajop\n",
    "\n",
    "\n",
    "\n",
    "def get_grads(net, patchnet, trainloader, max_batch, classes, chunk_idx,\n",
    "              kernel=(3,3), padding=(1,1),\n",
    "              stride=(1,1), layer_idx=0):\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    patchnet.eval()\n",
    "    patchnet.cuda()\n",
    "    M = 0\n",
    "    #M.cuda()\n",
    "    \n",
    "    # Num images for taking AGOP (Can be small for early layers)\n",
    "    MAX_NUM_IMGS = max_batch\n",
    "\n",
    "    for idx, batch in enumerate(trainloader):\n",
    "        print(\"Computing GOP for sample \" + str(idx) + \\\n",
    "              \" out of \" + str(MAX_NUM_IMGS))\n",
    "        imgs, _ = batch\n",
    "        #imgs=imgs[:]\n",
    "        with torch.no_grad():\n",
    "            imgs = imgs.cuda()        \n",
    "            # Run the first half of the network wrt to the current layer \n",
    "            ip = net.features[:layer_idx](imgs).cpu() #(n,s)\n",
    "            \n",
    "        #print(patches.shape)\n",
    "        M += egop(patchnet,ip.cuda(), classes, chunk_idx).cuda()\n",
    "        del imgs\n",
    "        torch.cuda.empty_cache()\n",
    "        if idx >= MAX_NUM_IMGS:\n",
    "            break\n",
    "    net.cpu()\n",
    "    patchnet.cpu()\n",
    "    return M\n",
    "\n",
    "def load_nn(net, init_net, layer_idx=0):\n",
    "   \n",
    "    count = 0\n",
    "    \n",
    "    # Get the layer_idx+1 th conv layer\n",
    "    #TODO: Add functionality to access classifier layers too.\n",
    "    for idx, m in enumerate(net.features):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            count += 1\n",
    "        if count-1 == layer_idx:\n",
    "            l_idx = idx\n",
    "            break\n",
    "    \n",
    "    patchnet = deepcopy(net)\n",
    "    \n",
    "    # Truncate all layers before l_idx.\n",
    "    patchnet.features = net.features[l_idx:]\n",
    "    \n",
    "    M = net.features[l_idx].weight.data\n",
    "    # Compute WW which is (s,s) matrix\n",
    "    M =torch.matmul(M.T, M)\n",
    "    M0 = init_net.features[l_idx].weight.data\n",
    "    # Compute W0tW0 which is (s,s) matrix\n",
    "    M0 =torch.matmul(M0.T, M0)\n",
    "    return net, patchnet, M, M0, l_idx\n",
    "\n",
    "\n",
    "def verify_NFA(net, init_net, trainloader, layer_idx=0, max_batch=10, classes=10, chunk_idx=1):\n",
    "\n",
    "\n",
    "    net, patchnet, M, M0, l_idx = load_nn(net, init_net, layer_idx=layer_idx)\n",
    "\n",
    "    i_val = correlation(M0.cuda(), M.cuda())\n",
    "    print(\"Correlation between Initial and Trained CNFM: \", i_val)\n",
    "\n",
    "    G = get_grads(net, patchnet, trainloader,  max_batch, classes, chunk_idx,\n",
    "                  layer_idx=l_idx)\n",
    "    print(\"Shape of grad matrix\",G.shape)\n",
    "    G = sqrt(G.cuda())\n",
    "    Gop = G.clone()\n",
    "    r_val = correlation(M.cuda(), G.cuda())\n",
    "    print(\"Correlation between Trained CNFM and AGOP: \", r_val)\n",
    "    print(\"Final: \", i_val, r_val)\n",
    "    return Gop\n",
    "\n",
    "def vis_transform_image(net, img, G, layer_idx=0):\n",
    "   #TODO: What to visualise for the FC layers?\n",
    "    count = -1\n",
    "    \n",
    "    # Computes WtW for the weights(ignoring its bias) of layer_idx+1 the conv layer\n",
    "    for idx, p in enumerate(net.parameters()):\n",
    "        if len(p.shape) > 1:\n",
    "            count += 1\n",
    "        if count == layer_idx:\n",
    "            M = p.data\n",
    "            _, ki, q, s = M.shape\n",
    "\n",
    "            M = M.reshape(-1, ki*q*s)\n",
    "            M = torch.einsum('nd, nD -> dD', M, M)\n",
    "            break\n",
    "\n",
    "    count = 0\n",
    "    l_idx = None\n",
    "    \n",
    "    # Get the layer_idx+1 conv layer \n",
    "    for idx, m in enumerate(net.features):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            print(m, count)\n",
    "            count += 1\n",
    "\n",
    "        if count-1 == layer_idx:\n",
    "            l_idx = idx\n",
    "            break\n",
    "\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    img = img.cuda()\n",
    "    img = net.features[:l_idx](img).cpu()\n",
    "    net.cpu()\n",
    "    \n",
    "    # If G is given which is expected to be the AGOP of layer_idx+1 conv layer then that is used.\n",
    "    if G is not None:\n",
    "        M = G\n",
    "\n",
    "    patches = patchify(img, (q, s), (1, 1))\n",
    "    \n",
    "    print(patches.shape)\n",
    "    # Patches should will be of the shape (n,w,h,c,q,s) not (n,w,h,q,s,c)\n",
    "    n, w, h, q, s, c = patches.shape\n",
    "    # Vectorize each patch\n",
    "    patches = patches.reshape(n, w, h, q*s*c)\n",
    "    # Apply either WtW or AGOP of the layer_idx+1 conv to each patch. D is c*q*s vector\n",
    "    M_patch = torch.einsum('nwhd, dD -> nwhD', patches, M) #(n,w,h,c*q*s)\n",
    "    \n",
    "    M_patch = norm(M_patch, dim=-1) #(n,w,h)\n",
    "\n",
    "    vis.image(min_max(M_patch[0])) #(w,h) image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87258fbe-c4b8-49d9-8319-74b5a72a4584",
   "metadata": {},
   "source": [
    "# Verify NFA for FC layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "206e8d75-2d15-4529-9bdf-325264efc42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.2370, device='cuda:0')\n",
      "Computing GOP for sample 0 out of 20\n",
      "Computing GOP for sample 1 out of 20\n",
      "Computing GOP for sample 2 out of 20\n",
      "Computing GOP for sample 3 out of 20\n",
      "Computing GOP for sample 4 out of 20\n",
      "Computing GOP for sample 5 out of 20\n",
      "Computing GOP for sample 6 out of 20\n",
      "Computing GOP for sample 7 out of 20\n",
      "Computing GOP for sample 8 out of 20\n",
      "Computing GOP for sample 9 out of 20\n",
      "Computing GOP for sample 10 out of 20\n",
      "Computing GOP for sample 11 out of 20\n",
      "Computing GOP for sample 12 out of 20\n",
      "Computing GOP for sample 13 out of 20\n",
      "Computing GOP for sample 14 out of 20\n",
      "Computing GOP for sample 15 out of 20\n",
      "Computing GOP for sample 16 out of 20\n",
      "Computing GOP for sample 17 out of 20\n",
      "Computing GOP for sample 18 out of 20\n",
      "Computing GOP for sample 19 out of 20\n",
      "Computing GOP for sample 20 out of 20\n",
      "Shape of grad matrix torch.Size([3072, 3072])\n",
      "Correlation between Trained CNFM and AGOP:  tensor(0.7101, device='cuda:0')\n",
      "Final:  tensor(0.2370, device='cuda:0') tensor(0.7101, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2016e-02, -3.6660e-04,  6.4364e-04,  ..., -1.7765e-03,\n",
       "          8.2688e-04,  7.2708e-06],\n",
       "        [-3.6529e-04,  2.4448e-02, -1.4750e-03,  ...,  1.6157e-03,\n",
       "         -6.3870e-04, -2.2715e-04],\n",
       "        [ 6.4223e-04, -1.4761e-03,  2.2138e-02,  ..., -9.7591e-04,\n",
       "          8.7749e-04, -5.8127e-04],\n",
       "        ...,\n",
       "        [-1.7785e-03,  1.6131e-03, -9.7762e-04,  ...,  2.5178e-02,\n",
       "          4.6532e-04,  1.2917e-04],\n",
       "        [ 8.2640e-04, -6.3988e-04,  8.7811e-04,  ...,  4.6324e-04,\n",
       "          2.3380e-02,  4.3505e-04],\n",
       "        [ 5.6838e-06, -2.2632e-04, -5.8024e-04,  ...,  1.3076e-04,\n",
       "          4.3773e-04,  2.3445e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(net)\n",
    "verify_NFA(net, init_net, trainloader, max_batch= 20, classes=10, chunk_idx=1, layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c3cb-e6fa-4e9f-b222-f1fa2845af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How to meaningfully visualise? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb970f08-c3a0-405d-8ac3-f3311e2f88f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd49e-4722-4f2d-887e-df6ad9b1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Warning: This is an extremely cpu intensive process since it uses solve function from linalg \n",
    "The rfm.py from utils is equipped with more memory efficient solvers. \n",
    "'''\n",
    "\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c26017-64bb-4682-8271-a349255271c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
