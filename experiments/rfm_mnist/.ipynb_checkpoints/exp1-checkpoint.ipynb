{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85af1c7-cc22-4007-a083-f2a298fb67bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93cae0-e62b-4ae4-a7a0-7a7e113b9a9d",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple 2 layer FC network on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1797532-a687-49c7-b3d7-5c5545f2eeaf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1588384-18ad-4c06-83e7-cb2d7ed5a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parent_dir='C:\\\\Users\\\\garav\\\\AGOP\\\\DLR'\n",
    "model_dir1= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model1\\\\nn_models\\\\'\n",
    "model_dir3= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model3\\\\nn_models\\\\'\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75d858f4-2bd3-43a4-8f4b-88b1978ff657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import agop_fc as af\n",
    "from utils import agop_fc1 as af1\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import rfm\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from trained_models.MNIST.model1 import trainer as t1\n",
    "from trained_models.MNIST.model3 import trainer as t3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d028bc-ee51-4fda-9f6b-206b84a1abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851228a2-b59b-41ff-bb5a-fc1af2c3f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3def1b-9d25-467e-ba0b-bfcd69fcdd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "torch.Size([5000, 3, 32, 32])\n",
      "Train Size:  40000 Val Size:  10000\n",
      "Test Size:  10000\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([892, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "torch.Size([900, 3, 32, 32])\n",
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t1.get_loaders()\n",
    "net= t1.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir1+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir1+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "\n",
    "#print(\"Train the network first\")\n",
    "#t1.train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23854c-2ed3-4576-b498-fc5093c410ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader, testloader = t3.get_loaders()\n",
    "net= t3.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir3+'mnist_fc_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir3+'mnist_fc_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Train the network first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87258fbe-c4b8-49d9-8319-74b5a72a4584",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Verify NFA for FC layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206e8d75-2d15-4529-9bdf-325264efc42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0')\n",
      "Computing GOP for sample 0 out of 50\n",
      "Computing GOP for sample 1 out of 50\n",
      "Computing GOP for sample 2 out of 50\n",
      "Computing GOP for sample 3 out of 50\n",
      "Computing GOP for sample 4 out of 50\n",
      "Computing GOP for sample 5 out of 50\n",
      "Computing GOP for sample 6 out of 50\n",
      "Computing GOP for sample 7 out of 50\n",
      "Computing GOP for sample 8 out of 50\n",
      "Computing GOP for sample 9 out of 50\n",
      "Computing GOP for sample 10 out of 50\n",
      "Computing GOP for sample 11 out of 50\n",
      "Computing GOP for sample 12 out of 50\n",
      "Computing GOP for sample 13 out of 50\n",
      "Computing GOP for sample 14 out of 50\n",
      "Computing GOP for sample 15 out of 50\n",
      "Computing GOP for sample 16 out of 50\n",
      "Computing GOP for sample 17 out of 50\n",
      "Computing GOP for sample 18 out of 50\n",
      "Computing GOP for sample 19 out of 50\n",
      "Computing GOP for sample 20 out of 50\n",
      "Computing GOP for sample 21 out of 50\n",
      "Computing GOP for sample 22 out of 50\n",
      "Computing GOP for sample 23 out of 50\n",
      "Computing GOP for sample 24 out of 50\n",
      "Computing GOP for sample 25 out of 50\n",
      "Computing GOP for sample 26 out of 50\n",
      "Computing GOP for sample 27 out of 50\n",
      "Computing GOP for sample 28 out of 50\n",
      "Computing GOP for sample 29 out of 50\n",
      "Computing GOP for sample 30 out of 50\n",
      "Computing GOP for sample 31 out of 50\n",
      "Computing GOP for sample 32 out of 50\n",
      "Computing GOP for sample 33 out of 50\n",
      "Computing GOP for sample 34 out of 50\n",
      "Computing GOP for sample 35 out of 50\n",
      "Computing GOP for sample 36 out of 50\n",
      "Computing GOP for sample 37 out of 50\n",
      "Computing GOP for sample 38 out of 50\n",
      "Computing GOP for sample 39 out of 50\n",
      "Computing GOP for sample 40 out of 50\n",
      "Computing GOP for sample 41 out of 50\n",
      "Computing GOP for sample 42 out of 50\n",
      "Computing GOP for sample 43 out of 50\n",
      "Computing GOP for sample 44 out of 50\n",
      "Computing GOP for sample 45 out of 50\n",
      "Computing GOP for sample 46 out of 50\n",
      "Computing GOP for sample 47 out of 50\n",
      "Computing GOP for sample 48 out of 50\n",
      "Computing GOP for sample 49 out of 50\n",
      "Computing GOP for sample 50 out of 50\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Correlation between Trained CNFM and AGOP:  tensor(0.5470, device='cuda:0')\n",
      "Final:  tensor(0.4899, device='cuda:0') tensor(0.5470, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1521,  0.0036,  0.0123,  ..., -0.0081, -0.0019,  0.0023],\n",
       "        [ 0.0036,  0.1669, -0.0310,  ...,  0.0210, -0.0045,  0.0172],\n",
       "        [ 0.0123, -0.0310,  0.1918,  ..., -0.0199, -0.0021, -0.0093],\n",
       "        ...,\n",
       "        [-0.0081,  0.0210, -0.0199,  ...,  0.1433,  0.0097,  0.0215],\n",
       "        [-0.0019, -0.0045, -0.0021,  ...,  0.0097,  0.1614,  0.0088],\n",
       "        [ 0.0023,  0.0172, -0.0093,  ...,  0.0215,  0.0088,  0.1550]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(net)\n",
    "af.verify_NFA(net, init_net, trainloader, max_batch= 50, classes=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdfd390-d9fa-4279-984b-a70d77281a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "Correlation between Initial and Trained CNFM:  tensor(0.4899, device='cuda:0', dtype=torch.float64)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "  (1): Nonlinearity()\n",
      ")\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Computing Jacobian for batch:  0 50\n",
      "Computing Jacobian for batch:  1 50\n",
      "Computing Jacobian for batch:  2 50\n",
      "Computing Jacobian for batch:  3 50\n",
      "Computing Jacobian for batch:  4 50\n",
      "Computing Jacobian for batch:  5 50\n",
      "Computing Jacobian for batch:  6 50\n",
      "Computing Jacobian for batch:  7 50\n",
      "Computing Jacobian for batch:  8 50\n",
      "Computing Jacobian for batch:  9 50\n",
      "Computing Jacobian for batch:  10 50\n",
      "Computing Jacobian for batch:  11 50\n",
      "torch.Size([9600, 10, 1024])\n",
      "0 12\n",
      "1 12\n",
      "2 12\n",
      "3 12\n",
      "4 12\n",
      "5 12\n",
      "6 12\n",
      "7 12\n",
      "8 12\n",
      "9 12\n",
      "10 12\n",
      "11 12\n",
      "Shape of grad matrix torch.Size([1024, 1024])\n",
      "Full Matrix Correlation Centered:  tensor(0.7705, device='cuda:0', dtype=torch.float64)\n",
      "Full Matrix Correlation Uncentered:  tensor(0.5471, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "af1.verify_NFA(net, init_net, trainloader, batch_size= 800, cutoff=10, chunk_idx=1, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c3cb-e6fa-4e9f-b222-f1fa2845af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How to meaningfully visualise? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb970f08-c3a0-405d-8ac3-f3311e2f88f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RFM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdd49e-4722-4f2d-887e-df6ad9b1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Warning: This is an extremely cpu intensive process since it uses solve function from linalg \n",
    "The rfm.py from utils is equipped with more memory efficient solvers. \n",
    "'''\n",
    "\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398c7f3-04d0-4d0e-a420-df7ce183c68a",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f2150c4-24f4-4514-a748-18d616c91dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#from numpy.linalg import solve\n",
    "from torch.linalg import solve\n",
    "import kernels #Should be called from utils\n",
    "from tqdm import tqdm\n",
    "import hickle\n",
    "import torch.distributions as distributions\n",
    "\n",
    "def laplace_kernel_M(pair1, pair2, bandwidth, M):\n",
    "    return kernels.laplacian_M(pair1, pair2, bandwidth, M)\n",
    "\n",
    "\n",
    "def get_grads(X, sol, L, P, batch_size=2):\n",
    "    M = 0.\n",
    "\n",
    "    num_samples = 10000\n",
    "    #indices = np.random.randint(len(X), size=num_samples)\n",
    "    indices = torch.randint(0, len(X), (num_samples,))\n",
    "\n",
    "    if len(X) > len(indices):\n",
    "        x = X[indices, :]\n",
    "    else:\n",
    "        x = X\n",
    "\n",
    "    K = laplace_kernel_M(X, x, L, P)\n",
    "\n",
    "    dist = kernels.euclidean_distances_M(X, x, P, squared=False)\n",
    "    dist = torch.where(dist < 1e-10, torch.zeros(1).float(), dist)\n",
    "\n",
    "    K = K/dist\n",
    "    K[K == float(\"Inf\")] = 0.\n",
    "\n",
    "    #a1 = torch.from_numpy(sol.T).float()\n",
    "    a1= sol.T\n",
    "    n, d = X.shape\n",
    "    n, c = a1.shape\n",
    "    m, d = x.shape\n",
    "\n",
    "    a1 = a1.reshape(n, c, 1)\n",
    "    X1 = (X @ P).reshape(n, 1, d)\n",
    "    step1 = a1 @ X1\n",
    "    del a1, X1\n",
    "    step1 = step1.reshape(-1, c*d)\n",
    "\n",
    "    step2 = K.T @ step1\n",
    "    del step1\n",
    "\n",
    "    step2 = step2.reshape(-1, c, d)\n",
    "\n",
    "    #a2 = torch.from_numpy(sol).float()\n",
    "    a2 = sol\n",
    "    step3 = (a2 @ K).T\n",
    "\n",
    "    del K, a2\n",
    "\n",
    "    step3 = step3.reshape(m, c, 1)\n",
    "    x1 = (x @ P).reshape(m, 1, d)\n",
    "    step3 = step3 @ x1\n",
    "\n",
    "    G = (step2 - step3) * -1/L\n",
    "\n",
    "    M = 0.\n",
    "\n",
    "    bs = batch_size\n",
    "    batches = torch.split(G, bs)\n",
    "    for i in tqdm(range(len(batches))):\n",
    "        grad = batches[i].cuda()\n",
    "        gradT = torch.transpose(grad, 1, 2)\n",
    "        M += torch.sum(gradT @ grad, dim=0).cpu()\n",
    "        del grad, gradT\n",
    "    torch.cuda.empty_cache()\n",
    "    M /= len(G)\n",
    "    #M = M\n",
    "\n",
    "    return M\n",
    "\n",
    "def sample_normal(covariance_matrix_M, num_rows_k, matrix_dim_t):\n",
    "   \n",
    "    # Create a mean vector of zeros, compatible with the dimensions of M\n",
    "    dtype = covariance_matrix_M.dtype\n",
    "    mean_vector = torch.zeros(matrix_dim_t, dtype=dtype, device=device)\n",
    "    mean_vector.to(device)\n",
    "    #covariance_matrix_M.to(device)\n",
    "    # Create a multivariate normal distribution object\n",
    "    # torch.distributions.MultivariateNormal expects a covariance_matrix.\n",
    "    # It internally checks for positive definiteness.\n",
    "    try:\n",
    "        mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MultivariateNormal distribution: {e}\")\n",
    "        print(\"Please ensure your covariance_matrix_M is symmetric positive definite.\")\n",
    "        # Attempt to make it PSD for robustness in example, by adding a small diagonal perturbation\n",
    "        # In a real scenario, you'd ensure your input M is correctly formed.\n",
    "        min_eigval = torch.min(torch.linalg.eigvalsh(covariance_matrix_M)).item()\n",
    "        if min_eigval <= 0:\n",
    "            print(f\"Warning: Covariance matrix has non-positive eigenvalue ({min_eigval:.2e}). Adding jitter.\")\n",
    "            covariance_matrix_M = covariance_matrix_M + torch.eye(matrix_dim_t, device=device, dtype=dtype) * (abs(min_eigval) + 1e-6)\n",
    "            mvn = distributions.MultivariateNormal(loc=mean_vector, covariance_matrix=covariance_matrix_M)\n",
    "\n",
    "\n",
    "    # Sample num_rows_k times from the distribution\n",
    "    # The .sample() method will return a tensor of shape (num_rows_k, matrix_dim_t)\n",
    "    sampled_matrix = mvn.sample((num_rows_k,))\n",
    "\n",
    "    return sampled_matrix\n",
    "\n",
    "def rfm(train_loader, val_loader, test_loader,\n",
    "        iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "        train_acc=True):\n",
    "\n",
    "    L = 10\n",
    "\n",
    "    X_train, y_train = get_data(train_loader)\n",
    "    X_val, y_val = get_data(val_loader)\n",
    "    X_test, y_test = get_data(test_loader)\n",
    "\n",
    "    # Trimming: Ideally should be avoided\n",
    "    X_train, y_train = X_train[:10000], y_train[:10000]\n",
    "    X_val, y_val = X_val[:10000], y_val[:10000]\n",
    "    X_test, y_test = X_test[:100], y_test[:100]\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "\n",
    "    M = torch.eye(d, dtype=torch.float32)\n",
    "    M.to(device)\n",
    "\n",
    "    for i in range(iters):\n",
    "        K_train = laplace_kernel_M(X_train, X_train, L, M)\n",
    "        K_train.to(device)\n",
    "        y_train.to(device)\n",
    "        #Todo: Does the below line use cpu or gpu escpecially the identity matrix.\n",
    "        source = (K_train + reg * torch.eye(len(K_train))).float()\n",
    "        sol = solve(source, y_train).T\n",
    "\n",
    "        if train_acc:\n",
    "            y_pred = (sol @ K_train).T\n",
    "            #y_pred = torch.from_numpy(preds)\n",
    "            preds = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds)\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "\n",
    "        K_test = laplace_kernel_M(X_train, X_test, L, M)\n",
    "        y_pred = (sol @ K_test).T\n",
    "        #print(\"Round \" + str(i) + \" MSE: \", torch.mean(torch.square(preds - y_test.numpy())))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", F.mse_loss(y_pred, y_test))\n",
    "        #y_pred = torch.from_numpy(preds)     \n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        count = torch.sum(labels == preds)\n",
    "        print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "\n",
    "        M  = get_grads(X_train, sol, L, M, batch_size=batch_size)\n",
    "        print(M.shape)\n",
    "        if name is not None:\n",
    "            hickle.dump(M, 'saved_Ms/M_' + name + '_' + str(i) + '.h')\n",
    "    W = sample_normal(M.to(device), 1024,3072)\n",
    "    print(W)\n",
    "    print(net.features[0].weight)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    K_train = laplace_kernel_M(X_train, X_train, L, torch.from_numpy(M)).numpy()\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train).T\n",
    "    K_test = laplace_kernel_M(X_train, X_test, L, torch.from_numpy(M)).numpy()\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    y_pred = torch.from_numpy(preds)\n",
    "    preds = torch.argmax(y_pred, dim=-1)\n",
    "    labels = torch.argmax(y_test, dim=-1)\n",
    "    count = torch.sum(labels == preds).numpy()\n",
    "    print(\" Final Acc: \", count / len(labels))\n",
    "    '''\n",
    "    #return mse\n",
    "\n",
    "\n",
    "def get_data(loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx, batch in enumerate(loader):\n",
    "        inputs, labels = batch\n",
    "        X.append(inputs)\n",
    "        y.append(labels)\n",
    "    return torch.cat(X, dim=0), torch.cat(y, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f8234842-3ac3-4786-a6cf-73c694431976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 Train Acc:  tensor(1.)\n",
      "Round 0 MSE:  tensor(0.0064)\n",
      "Round 0 Acc:  tensor(0.9900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:28<00:00, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072])\n",
      "Error creating MultivariateNormal distribution: Expected parameter covariance_matrix (Tensor of shape (3072, 3072)) of distribution MultivariateNormal(loc: torch.Size([3072]), covariance_matrix: torch.Size([3072, 3072])) to satisfy the constraint PositiveDefinite(), but found invalid values:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Please ensure your covariance_matrix_M is symmetric positive definite.\n",
      "Warning: Covariance matrix has non-positive eigenvalue (-1.52e-09). Adding jitter.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 88\u001b[0m, in \u001b[0;36msample_normal\u001b[1;34m(covariance_matrix_M, num_rows_k, matrix_dim_t)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     mvn \u001b[38;5;241m=\u001b[39m distributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(loc\u001b[38;5;241m=\u001b[39mmean_vector, covariance_matrix\u001b[38;5;241m=\u001b[39mcovariance_matrix_M)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\distributions\\multivariate_normal.py:180\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[1;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[0;32m    179\u001b[0m event_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(batch_shape, event_shape, validate_args\u001b[38;5;241m=\u001b[39mvalidate_args)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_tril \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\distributions\\distribution.py:71\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 71\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter covariance_matrix (Tensor of shape (3072, 3072)) of distribution MultivariateNormal(loc: torch.Size([3072]), covariance_matrix: torch.Size([3072, 3072])) to satisfy the constraint PositiveDefinite(), but found invalid values:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfm(trainloader, valloader, testloader, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      2\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[108], line 157\u001b[0m, in \u001b[0;36mrfm\u001b[1;34m(train_loader, val_loader, test_loader, iters, name, batch_size, reg, train_acc)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         hickle\u001b[38;5;241m.\u001b[39mdump(M, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_Ms/M_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m W \u001b[38;5;241m=\u001b[39m sample_normal(M, \u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m3072\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(W)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(net\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight)\n",
      "Cell \u001b[1;32mIn[108], line 97\u001b[0m, in \u001b[0;36msample_normal\u001b[1;34m(covariance_matrix_M, num_rows_k, matrix_dim_t)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m min_eigval \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Covariance matrix has non-positive eigenvalue (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_eigval\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Adding jitter.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m         covariance_matrix_M \u001b[38;5;241m=\u001b[39m covariance_matrix_M \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(matrix_dim_t, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mabs\u001b[39m(min_eigval) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m     98\u001b[0m         mvn \u001b[38;5;241m=\u001b[39m distributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(loc\u001b[38;5;241m=\u001b[39mmean_vector, covariance_matrix\u001b[38;5;241m=\u001b[39mcovariance_matrix_M)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Sample num_rows_k times from the distribution\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# The .sample() method will return a tensor of shape (num_rows_k, matrix_dim_t)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "rfm(trainloader, valloader, testloader, name=None,\n",
    "            batch_size=10, iters=1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0aaba271-fa28-45eb-8d17-6496e380466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(net.features[0].weight.shape)\n",
    "print(net.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28cc78e1-b6fe-49bc-b957-10c67afd2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "    (1): Nonlinearity()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "    (3): Nonlinearity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f329e-fd21-4f0f-b069-94330314d27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
