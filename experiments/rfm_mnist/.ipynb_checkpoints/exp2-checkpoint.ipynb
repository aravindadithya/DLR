{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132b5a3f-434a-480b-b700-57080e223ebe",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fdfce-6606-49d9-8a09-30882b61807b",
   "metadata": {},
   "source": [
    "This experiment checks the following for a simple convnet on MNIST.\n",
    "1. Verify Agop and NFM relations for the conv layers\n",
    "2. Run RFM to construct similar matrices as the above.(TBD)\n",
    "\n",
    "The model is taken from MNIST/model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20927ac7-5a3a-47f7-b1c3-4ab1da39990d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b908e4f-a112-4597-85f8-3bd750a99aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parent_dir='C:\\\\Users\\\\garav\\\\AGOP\\\\DLR'\n",
    "model_dir= 'C:\\\\Users\\\\garav\\\\AGOP\\\\DLR\\\\trained_models\\\\MNIST\\\\model2\\\\nn_models\\\\'\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a63f9a-f5d9-452f-a906-f07545fd3d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import trainer as t\n",
    "from utils import agop_conv as agc\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import rfm\n",
    "import numpy as np\n",
    "from trained_models.MNIST.model2 import model2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f9d450-8db0-4963-9a9e-dfaff72b63f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed7a279d-7a07-49a0-85e6-615dfa1faf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5718b190-5522-4792-a8a4-266f626a7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # Mean and standard deviation for MNIST\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset, valset = train_test_split(trainset, train_size=0.8)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=100,\n",
    "                                            shuffle=False, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27fadb-e250-4014-98c2-1884c7d179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,imgs = next(enumerate(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cded235-9de2-4943-8dc5-2a6d5c02b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= model2.ConvNet()\n",
    "init_net=deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b08968a-712a-43b0-adb2-49fd2ff16c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(model_dir+'mnist_conv_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir+'mnist_conv_trained_nn.pth', map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    t.train_network(trainloader, valloader, testloader,\n",
    "                    num_classes=10, root_path= model_dir,\n",
    "                    optimizer= optim.Adam(net.parameters(), lr=0.001), \n",
    "                    lfn= nn.CrossEntropyLoss(),\n",
    "                    name='mnist_conv', net=net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a974e0-9a54-4d0f-aafc-d04211dfdb7d",
   "metadata": {},
   "source": [
    "# Verify NFA for conv layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c8f4db-df8e-4504-8a06-29da71044e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Initial and Trained CNFM:  tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Computing GOP for sample 0 out of 10\n",
      "Computing GOP for sample 1 out of 10\n",
      "Computing GOP for sample 2 out of 10\n",
      "Computing GOP for sample 3 out of 10\n",
      "Computing GOP for sample 4 out of 10\n",
      "Computing GOP for sample 5 out of 10\n",
      "Computing GOP for sample 6 out of 10\n",
      "Computing GOP for sample 7 out of 10\n",
      "Computing GOP for sample 8 out of 10\n",
      "Computing GOP for sample 9 out of 10\n",
      "Computing GOP for sample 10 out of 10\n",
      "Correlation between Trained CNFM and AGOP:  tensor(0.9106, device='cuda:0')\n",
      "Final:  tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9106, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Here layer_idx refers to layer_idx+1 th conv layer. \n",
    "G = agc.verify_NFA(net.to(device), init_net.to(device), trainloader, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b316c9-db51-49a5-8cf8-22d964ff5a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 3, 3])\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) 0\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) 1\n",
      "torch.Size([64, 14, 14, 32, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) 0\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) 1\n",
      "torch.Size([64, 14, 14, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "agc.vis_transform_image(net, imgs[0], None, layer_idx=1)\n",
    "agc.vis_transform_image(net, imgs[0], G, layer_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62deddfd-2ffd-4da7-86ec-86e6b572ee92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
