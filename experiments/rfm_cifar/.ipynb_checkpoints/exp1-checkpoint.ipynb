{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256f69c6-5615-448f-a4f9-b2739dc20d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = os.path.join('/work/DLR','trained_models', 'CIFAR', 'model2', 'nn_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e0afc-223e-4a6b-a086-ff70b0c3fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import agop_gcnn as agc\n",
    "from utils import trainer as tr\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "#import rfm\n",
    "import numpy as np\n",
    "from trained_models.CIFAR.model2 import trainer as t\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from utils.groupy.gconv.pytorch_gconv.splitgconv2d import P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M\n",
    "from groupy.gconv.make_gconv_indices import *\n",
    "from copy import deepcopy\n",
    "from torch.nn.functional import pad\n",
    "from torch.func import jacrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b68b66e-8512-4711-9a5d-aa69b405766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac20e0ec-28da-4100-873e-6f753b98db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696099c8-5935-435e-b5b1-334086a8fe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (features): Sequential(\n",
      "    (0): P4MConvZ2()\n",
      "    (1): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(91, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (features): Sequential(\n",
      "        (0): P4MConvP4M()\n",
      "        (1): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): P4MConvP4M()\n",
      "        (4): BatchNorm3d(181, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (lrelu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=1448, out_features=10, bias=True)\n",
      ")\n",
      "Total number of trainable parameters in ResNet: 21350863\n"
     ]
    }
   ],
   "source": [
    "net= t.get_untrained_net()\n",
    "print(net)\n",
    "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters in ResNet: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2531ad31-a6b8-47a1-9e49-b1bac24307d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = t.get_loaders()\n",
    "#net= t.get_untrained_net()\n",
    "init_net= deepcopy(net)\n",
    "import os\n",
    "if os.path.exists(model_dir+'cifar_gcnn_trained_nn.pth'):\n",
    "    checkpoint = torch.load(model_dir+'cifar_gcnn_trained_nn.pth', map_location=torch.device(device), weights_only=True)\n",
    "    net.load_state_dict(checkpoint['state_dict'])  # Access the 'state_dict' within the loaded dictionary\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "\n",
    "#print(\"Train the network first\")\n",
    "#t.train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eaab4fc-baaa-4d66-b98b-8637328dc68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.14\n"
     ]
    }
   ],
   "source": [
    "#tr.visualize_predictions(net, testloader, range(10), device, num_images=36)\n",
    "print(tr.get_acc_ce(net.to(device), testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fbf30e-27a1-45ce-ba61-94046b5189af",
   "metadata": {},
   "source": [
    "# Debug: Agop verification for Resnet Gcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ebf18e-0c4d-4c78-84b3-370fdbb292de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    }
   ],
   "source": [
    "''' This module does the following\n",
    "1. Scan the network for conv layers\n",
    "2. For each gcnn conv layer compute W^TW of eq 3\n",
    "3. For each gcnn conv layer compute the AGOP(AJOP in case of multiple outputs)\n",
    "4. For each gcnn conv layer print the pearson correlation between 2 and 3\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.func import jacrev\n",
    "from torch.nn.functional import pad\n",
    "from torch.linalg import norm, svd\n",
    "from torchvision import models\n",
    "import visdom\n",
    "from torch.linalg import norm, eig\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.linalg import norm\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from utils.groupy.gconv.pytorch_gconv.splitgconv2d import P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M\n",
    "from trained_models.CIFAR.model2.model2 import BasicBlock, Bottleneck\n",
    "from groupy.gconv.make_gconv_indices import *\n",
    "from copy import deepcopy\n",
    "\n",
    "SEED = 2323\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "vis = visdom.Visdom('http://127.0.0.1', use_incoming_socket=False)\n",
    "vis.close(env='main')\n",
    "\n",
    "def patchify(x, in_channels, ip_stab, patch_size, stride_size, padding=None, pad_type='zeros'):\n",
    "    '''\n",
    "        Given an input image (n,c,h,w) generate (n,w_out,h_out,c,q,s) respecting stride,padding, \n",
    "        w_out is number of pathces along the width for the given stride after padding\n",
    "        h_out is number of pathces along the height for the given stride after padding\n",
    "        (q,s) is the kernel dimensions \n",
    "    '''\n",
    "    input_shape = x.size()\n",
    "    #TODO: The last two shapes look swapped. This was the same order in cohens code too. For square ips \n",
    "    #there is no effect. However for rect ips what would happen?\n",
    "    x = x.view(input_shape[0], in_channels*ip_stab, input_shape[-2], input_shape[-1])\n",
    "    #x = x.view(input_shape[0], in_channels*ip_stab, input_shape[-2], input_shape[-1])\n",
    "    q1, q2 = patch_size\n",
    "    s1, s2 = stride_size\n",
    "    #print(\"Image Shape\",x.shape)\n",
    "    if padding is None:\n",
    "        pad_1 = (q1-1)//2\n",
    "        pad_2 = (q2-1)//2\n",
    "    else:\n",
    "        pad_1, pad_2 = padding\n",
    "\n",
    "    pad_dims = (pad_2, pad_2, pad_1, pad_1)\n",
    "    if pad_type == 'zeros':\n",
    "        x = pad(x, pad_dims)\n",
    "    elif pad_type == 'circular':\n",
    "        x = pad(x, pad_dims, 'circular')\n",
    "        \n",
    "    patches = x.unfold(2, q1, s1).unfold(3, q2, s2) #(n, c, h_out, w_out, q, s)\n",
    "    #print(\"Image Shape1\",patches.shape)\n",
    "    patches = patches.transpose(1, 3).transpose(1, 2) #(n,w_out,h_out,c,q,s) \n",
    "    #print(\"Image Shape2\",patches.shape)\n",
    "    return patches\n",
    "\n",
    "def trans_filter(w, inds):\n",
    "    inds_reshape = inds.reshape((-1, inds.shape[-1])).astype(np.int64)\n",
    "    w_indexed = w[:, :, inds_reshape[:, 0].tolist(), inds_reshape[:, 1].tolist(), inds_reshape[:, 2].tolist()]\n",
    "    w_indexed = w_indexed.view(w_indexed.size()[0], w_indexed.size()[1],\n",
    "                                    inds.shape[0], inds.shape[1], inds.shape[2], inds.shape[3])\n",
    "    w_transformed = w_indexed.permute(0, 2, 1, 3, 4, 5)\n",
    "    return w_transformed.contiguous()\n",
    "    \n",
    "class PatchConvLayer(nn.Module):\n",
    "    def __init__(self, conv_layer):\n",
    "        super().__init__()\n",
    "        self.layer = conv_layer #(k,c,q,s)\n",
    "        #inds = make_c4_z2_indices(self.layer.ksize)\n",
    "       \n",
    "    def forward(self, patches):\n",
    "        tw = trans_filter(self.layer.weight, self.layer.inds)\n",
    "        tw_shape = (self.layer.out_channels * self.layer.output_stabilizer_size,\n",
    "                    self.layer.in_channels * self.layer.input_stabilizer_size,\n",
    "                    self.layer.ksize, self.layer.ksize)\n",
    "        tw = tw.view(tw_shape)\n",
    "        #print(\"tw shape\",tw.shape)\n",
    "        #print(\"Patch_shape\", patches.shape)\n",
    "        out = torch.einsum('nhwcqr, kcqr -> nhwk', patches, tw)\n",
    "        n, w, h, k = out.shape\n",
    "        out = out.transpose(1, 3).transpose(2, 3) #(n,k,h_out,w_out)\n",
    "        out = out.view(n, self.layer.out_channels, self.layer.output_stabilizer_size, h, w)\n",
    "        #print(\"out_shape\", out.shape)\n",
    "        return out\n",
    "\n",
    "class PatchBasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, block_layer):\n",
    "        super().__init__()\n",
    "        self.layer = block_layer\n",
    "\n",
    "    # x is patches instead of images\n",
    "    def forward(self, X):\n",
    "        x, y = X\n",
    "        ops = self.layer\n",
    "        _, _, _, _, q, s = y.shape\n",
    "        z = y[:, :, :, :, (q-1)//2, (s-1)//2]\n",
    "        z = z.transpose(1, 3).transpose(2, 3)\n",
    "\n",
    "        s1, s2 = ops.features[0].stride\n",
    "        x = x[:, ::s1, ::s2, :, :, :]\n",
    "        o = ops(x)\n",
    "        '''\n",
    "        o = ops.features[0](x).contiguous()\n",
    "        o = ops.features[1](o)\n",
    "        o = ops.features[2](o)\n",
    "        o = ops.features[3](o)\n",
    "        o = ops.features[4](o)\n",
    "        '''\n",
    "        #if self.downsample:\n",
    "        z = ops.shortcut(z)\n",
    "        o += z\n",
    "        o = ops.lrelu(o)\n",
    "        return o\n",
    "\n",
    "def get_jacobian(net, data, c_idx=0, chunk=100):\n",
    "    with torch.no_grad():\n",
    "        def single_net(x):\n",
    "            # x is (w_out,h_out,c,q,s)\n",
    "            return net(x.unsqueeze(0))[:,c_idx*chunk:(c_idx+1)*chunk].squeeze(0)\n",
    "        # Parallelize across the images.\n",
    "        return torch.vmap(jacrev(single_net))(data) #(n, chunk, w_out, h_out, c, q, s)\n",
    "\n",
    "def egop(model, z):\n",
    "    ajop = 0\n",
    "    c = 10\n",
    "    chunk_idxs = 1\n",
    "    #Chunking is done to compute jacobian as chunks. This saves memory\n",
    "    #TODO: chunk should be passed as argument\n",
    "    chunk = c // chunk_idxs\n",
    "    for i in range(chunk_idxs):\n",
    "        J = get_jacobian(model, z, c_idx=i, chunk=chunk)\n",
    "        n, c, w, h, _, _, _ = J.shape\n",
    "        J = J.transpose(1, 3).transpose(1, 2) #(n, w_out, h_out, chunk, c, q, s)\n",
    "        grads = J.reshape(n*w*h, c, -1) #(n*w_out*h_out, chunk, c*q*s)\n",
    "        #Clarify: Where is mean taken\n",
    "        ajop += torch.einsum('ncd, ncD -> dD', grads, grads) #(c*q*s,c*q*s)\n",
    "    return ajop\n",
    "\n",
    "\n",
    "def load_nn(net, init_net, layer_idx=0):\n",
    "    \n",
    "    count = 0\n",
    "    # Get the layer_idx+1 th conv layer\n",
    "    for idx, m in enumerate(net.features):\n",
    "        if isinstance(m, (P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M, BasicBlock, Bottleneck)):\n",
    "            count += 1\n",
    "        if count-1 == layer_idx:\n",
    "            l_idx = idx\n",
    "            break\n",
    "\n",
    "    print(\"l_idx\",l_idx)\n",
    "    if(isinstance(net.features[l_idx],(P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M))):\n",
    "        \n",
    "        # Construct patchnet\n",
    "        patchnet = deepcopy(net)\n",
    "        temp = deepcopy(net.features[l_idx])\n",
    "        layer = PatchConvLayer(temp)\n",
    "        \n",
    "        #Truncate all layers before l_idx    \n",
    "        patchnet.features = net.features[l_idx:]\n",
    "        patchnet.features[0] = layer\n",
    "        \n",
    "        #layer whose CNFM we need\n",
    "        layer = deepcopy(net.features[l_idx])\n",
    "        layer_init = deepcopy(init_net.features[l_idx])     \n",
    "        \n",
    "    else:   \n",
    "        \n",
    "        # Construct patchnet\n",
    "        patchnet = deepcopy(net)\n",
    "        temp_block = deepcopy(net.features[l_idx])\n",
    "        layer = PatchConvLayer(temp_block.features[0])\n",
    "        temp_block.features[0]= layer\n",
    "        temp_block = PatchBasicBlock(temp_block)\n",
    "        \n",
    "        #Truncate all layers before l_idx    \n",
    "        patchnet.features = net.features[l_idx:]\n",
    "        patchnet.features[0] = temp_block\n",
    "        \n",
    "        #layer whose CNFM we need\n",
    "        layer = deepcopy(net.features[l_idx].features[0])\n",
    "        layer_init = deepcopy(init_net.features[l_idx].features[0])        \n",
    "    \n",
    "    # Extract all the meta info of the current conv layer.\n",
    "    (q, s) = layer.kernel_size\n",
    "    (pad1, pad2) = layer.padding\n",
    "    (s1, s2) = layer.stride \n",
    "    in_channels = layer.in_channels\n",
    "    input_stabilizer_size = layer.input_stabilizer_size\n",
    "    \n",
    "    # Extract W matrix\n",
    "    tw = trans_filter(layer.weight, layer.inds)\n",
    "    tw_shape = (layer.out_channels * layer.output_stabilizer_size,\n",
    "                        layer.in_channels * layer.input_stabilizer_size,\n",
    "                        layer.ksize, layer.ksize)\n",
    "    M = tw.view(tw_shape)\n",
    "    \n",
    "    tw= trans_filter(layer_init.weight, layer_init.inds)\n",
    "    tw_shape = (layer_init.out_channels * layer_init.output_stabilizer_size,\n",
    "                        layer_init.in_channels * layer_init.input_stabilizer_size,\n",
    "                        layer_init.ksize, layer_init.ksize)\n",
    "    M0 = tw.view(tw_shape)\n",
    "    \n",
    "    k, ki, q,s= M.shape\n",
    "                \n",
    "    # Build W which is a (k, c*q*s) matrix. What to do with ip_stab\n",
    "    M = M.reshape(-1, ki*q*s)\n",
    "                \n",
    "    # Compute WtW which is (c*q*s,c*q*s) matrix\n",
    "    M = torch.einsum('nd, nD -> dD', M, M)\n",
    "\n",
    "    k, ki, q,s= M0.shape\n",
    "\n",
    "    # Build W which is a (k, c*q*s) matrix. What to do with ip_stab\n",
    "    M0 = M0.reshape(-1, ki*q*s)\n",
    "\n",
    "    # Compute WtW which is (c*q*s,c*q*s) matrix\n",
    "    M0 = torch.einsum('nd, nD -> dD', M0, M0)\n",
    "\n",
    "    return net, patchnet, M, M0, l_idx, [(q, s), (pad1,pad2), (s1,s2)], in_channels, input_stabilizer_size\n",
    "\n",
    "\n",
    "def get_grads(net, in_channels, input_stabilizer_size, patchnet, trainloader,\n",
    "              kernel=(3,3), padding=(1,1),\n",
    "              stride=(1,1), layer_idx=0):\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    patchnet.eval()\n",
    "    patchnet.cuda()\n",
    "    M = 0\n",
    "    q, s = kernel\n",
    "    pad1, pad2 = padding\n",
    "    s1, s2 = stride\n",
    "\n",
    "    # Num images for taking AGOP (Can be small for early layers)\n",
    "    MAX_NUM_IMGS = 10\n",
    "\n",
    "    for idx, batch in enumerate(trainloader):\n",
    "        print(\"Computing GOP for sample \" + str(idx) + \\\n",
    "              \" out of \" + str(MAX_NUM_IMGS))\n",
    "        imgs, _ = batch\n",
    "        imgs= imgs.double()\n",
    "        with torch.no_grad():\n",
    "            imgs = imgs.cuda()        \n",
    "            # Run the first half of the network wrt to the current layer \n",
    "            imgs = net.features[:layer_idx](imgs).cpu() #(n,c,h,w)\n",
    "        patches = patchify(imgs, in_channels, input_stabilizer_size, \n",
    "                           (q, s), (s1,s2), padding=(pad1,pad2))#(n,w_out,h_out,c,q,s)\n",
    "        patches = patches.cuda()\n",
    "        #print(patches.shape)\n",
    "        M += egop(patchnet, patches).cpu()\n",
    "        del imgs, patches\n",
    "        torch.cuda.empty_cache()\n",
    "        if idx >= MAX_NUM_IMGS:\n",
    "            break\n",
    "    net.cpu()\n",
    "    patchnet.cpu()\n",
    "    return M\n",
    "\n",
    "\n",
    "def min_max(M):\n",
    "    return (M - M.min()) / (M.max() - M.min())\n",
    "\n",
    "\n",
    "def correlation(A, B):\n",
    "    M1 = A.clone()\n",
    "    M2 = B.clone()\n",
    "    M1 -= M1.mean()\n",
    "    M2 -= M2.mean()\n",
    "\n",
    "    norm1 = norm(M1.flatten())\n",
    "    norm2 = norm(M2.flatten())\n",
    "\n",
    "    return torch.sum(M1.cuda() * M2.cuda()) / (norm1 * norm2)\n",
    "\n",
    "\n",
    "def verify_NFA(net, init_net, trainloader, layer_idx=0):\n",
    "\n",
    "    net = net.double()\n",
    "    init_net = init_net.double()\n",
    "    net, patchnet, M, M0, l_idx, conv_vals, in_channels, input_stabilizer_size = load_nn(net,\n",
    "                                                     init_net,\n",
    "                                                     layer_idx=layer_idx)\n",
    "    (q, s), (pad1, pad2), (s1, s2) = conv_vals\n",
    "  \n",
    "\n",
    "    G = get_grads(net, in_channels, input_stabilizer_size, patchnet, trainloader,\n",
    "                  kernel=(q, s),\n",
    "                  padding=(pad1, pad2),\n",
    "                  stride=(s1, s2),\n",
    "                  layer_idx=l_idx)\n",
    "    \n",
    "    print(\"Shape after gradients: \", G.shape)\n",
    "    G = sqrt(G)\n",
    "    Gop = G.clone()\n",
    "    \n",
    "    print(\"Correlation between Initial and Trained CNFM: \", correlation(M0, M))\n",
    "    print(\"Correlation between Initial CNFM and Trained AGOP: \", correlation(M0, G))\n",
    "    print(\"Correlation between Trained CNFM and Trained AGOP: \", correlation(M, G))\n",
    "\n",
    "    #print(\"Final: \", i_val, r_val)\n",
    "    return Gop \n",
    "    #return i_val.data.numpy(), r_val.data.numpy()\n",
    "\n",
    "\n",
    "\n",
    "def sqrt(G):\n",
    "    U, s, Vt = svd(G)\n",
    "    s = torch.pow(s, 1./2)\n",
    "    G = U @ torch.diag(s) @ Vt\n",
    "    return G\n",
    "\n",
    "\n",
    "#TODO: ADD a visualizer for the image\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755d907-7e88-40da-85e0-a0b787b8261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_idx 0\n",
      "Computing GOP for sample 0 out of 10\n"
     ]
    }
   ],
   "source": [
    "verify_NFA(net, init_net, trainloader, layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ef7ad-ab9c-42cb-b88c-5faab090ff18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
